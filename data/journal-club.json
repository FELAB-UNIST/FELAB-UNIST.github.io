[
  {
    "date": "2025년 08월 21일",
    "title": "Retrieval augmented diffusion models for time series forecasting",
    "presenter": "Juchan Kim",
    "reason": "Retrieval + Time series forecasting 컨셉을 가져왔지만 백본으로 디퓨전 모델을 사용했다는 점에서 신기해서 가져와봤습니다. 논문에서도 diffusion model을 historical time series를 refer하는 retrieval algorithm로부터 모델에 conditioning을 주는 방법을 주로 논하고, 실험적으로 해당 방법론의 성능을 확인하였습니다. 일반적인 시계열 데이터(금융 분야처럼 description이 쉽게 주어져 있지 않은 경우)에도 적용해볼법한 연구라고 보여집니다. 최근 time series forecasting과 retrieval concept을 섞는게 많이 나오는 만큼, 관련 분야들에 대해서도 함께 발표하도록 하겠습니다.",
    "url": "https://arxiv.org/abs/2410.18712"
  },
  {
    "date": "2025년 08월 21일",
    "title": "mKG-RAG: Multimodal Knowledge Graph-Enhanced RAG for Visual Question Answering",
    "presenter": "Inwoo Tae",
    "reason": "위 논문은 멀티모달 정보가 혼재된 환경에서 보다 신뢰성 있는 RAG(Retrieval-Augmented Generation)를 구현하기 위해 멀티모달 Knowledge Graph 기반 RAG(mKG-RAG) 프레임워크를 제안합니다. 기존의 멀티모달 RAG가 단순히 이미지와 텍스트를 함께 불러와 LLM에 전달하는 방식에 머물렀다면, 본 연구는 각 모달리티의 엔티티와 관계를 Knowledge Graph(KG) 구조로 정규화하여 노이즈를 줄이고 의미적 정합성을 보장한다는 점이 핵심입니다. 특히 이미지에서 추출된 객체와 텍스트 내 개념들을 KG 상에서 연결하고, LLM은 이 그래프를 기반으로 추론을 수행함으로써 멀티모달 환경에서 더 정확하고 일관된 답변을 생성할 수 있음을 보였습니다. 여러 QA 벤치마크 실험에서도 KG 기반 구조화가 단순 멀티모달 입력 대비 안정적 성능 향상을 이끌어냈습니다. 따라서 이 논문은 멀티모달 RAG에서 KG의 필요성을 분명히 보여주기에 발표 주제로 선정하였습니다.",
    "url": "https://www.arxiv.org/pdf/2508.05318"
  },
  {
    "date": "2025년 08월 12일",
    "title": "TRACE: Grounding Time Series in Context for Multimodal Embedding and Retrieval",
    "presenter": "Junhyeong Lee",
    "reason": "위 논문은 시계열에서의 Multimodal retreival 연구입니다. 지난번에 주찬학생이 발표했던 논문과 어느정도 연관성이 있을 것 같습니다.\nTime series forecasting이 LLMs을 이용하도록 많이 연구되면서 Times series retrieval system까지 나타나게 되었는데요, 이런 기존 연구들은 contextual information이 충분히 활용되지 못하고 제대로 된 힘을 발휘하지 못하는 경우가 대부분이었습니다.\n이런 한계를 극복하기 위하여 1. TS Eoncder Pre-training, 2. Multimodal Alignment Learning 의 2 stages를 통해 학습을 하게 됩니다.\n23년, 24년 매 ICAIF를 갈 때 마다, 이런 retreival을 활용하여 의사결정에 도움을 줄 수 있지 않을까? 라는 생각을 많이 했었는데 해당 논문을 읽으면서 같이 해당 방향성에 대한 말씀들을 나누면 재밌을 것 같아서 선정하게 되었습니다.\n특히, 금융은 이런 contextual 데이터가 다른 도메인들에 비해서 더 풍부하게 영향을 줄 수 있을 것 같아서 금융 쪽에 어떻게 적용하면 좋을지 이야기 나눌 수 있으면 좋을 것 같습니다.",
    "url": "https://arxiv.org/pdf/2506.09114"
  },
  {
    "date": "2025년 08월 12일",
    "title": "Unveiling Causal Reasoning in Large Language Models: Reality or Mirage?",
    "presenter": "Sangjin Jin",
    "reason": "위 논문은 LLM의 인과추론(causal reasoning) 능력에 대한 근본적인 의문을 제기하는 연구로써, 현재 LLM의 인과추론 성능은 데이터로부터 학습한 내용에 대한 얕은 추론에 가까움을 실증적으로 입증하며, 이를 해결할 수 있는 접근법을 제시합니다.\n저자는 LLM의 autoregressive한 특성이 순차적인 예측을 제공할뿐 인과적인 추론에 기여하지 않는다는 점을 지적하며, 인과추론을 두 개의 레벨(Level-1, Level-2)로 구분하고, fresh 벤치마크 데이터로부터 LLM의 인과추론이 대부분 Level-1 (학습 내용)에 머물러 있음을 확인하였습니다. 이에, 인간의 추론 메커니즘에서 영감을 얻은 G2-Reasoner를 제안하며 RAG을 결합한 LLM에게 인과관계를 식별하도록 유도하여, LLM의 인과추론 능력이 Level-2 수준의 근접할 수 있음을 보여줍니다.\n\n최근 한화생명과의 산학과제에서도 거론되었듯이, LLM이 금융시장에서의 복잡한 상호작용을 진정 이해하고, 투자자에게 유용한 인사이트를 제공해줄 수 있는지에 대해서 고민해볼 수 있었습니다. 특히, 여러 거시변수들이 자산 가격에 미치는 복잡한 인과관계에 대해서는 LLM이 이를 정확히 파악하기란 어려움이 있을 것이라 생각했는데, 이런 분야에서 LLM의 capabilities와 나아가야할 방향에 대해 알아보기에 좋은 논문일 것 같습니다!",
    "url": "https://arxiv.org/abs/2506.21215"
  },
  {
    "date": "2025년 07월 30일",
    "title": "From Tasks to Teams: A Risk-First Evaluation Framework for Multi-Agent LLM Systems in Finance",
    "presenter": "Junhyuk Seo",
    "reason": "랩실에서 LLM연구와 Agent관련해서 이야기를 하며, LLM Agent가 금융에서 잘 작동하는 것도 좋지만 과연 그 시스템에 있어서 위험 요소에 대한 판단이 고려되고 있는가도 중요한 포인트라는 이야기를 나눈적이 있습니다.\n\n최근 금융 분야에서 여러 LLM agent들이 협력하여 거래,리스크 분석 등에 활용되는데, 기존 벤치마크들이나 개별 모델 정확도만으로는 시스템 전체의 리스크를 평가하기 어렵다는 문제가 제기됩니다.\n이에 저자들은 팀 단위 LLM 에이전트를 정량적,정성적으로 평가할 수 있는 프레임워크인 M-SAEA를 제안합니다.\n이 시스템은 모델, 워크플로우, 상호작용, 시스템의 4개 계층에 대해 총 10가지 risk axis를 기준으로 점수화합니다.\n특히,  temporal staleness, cross-agent race conditions, API-stress fragility 등 기존 벤치마크로 포착되지 않는 위험 요소들을 효과적으로 식별하며, 실험을 통해 M-SAEA는 낮은 latency cost로 치명적 오류 발생률을 줄일 수 있음을 보여주기도 합니다.\n이로써 LLM 에이전트 시스템의 '정확도 중심 평가'에서 '리스크 중심 평가'로의 전환 필요성을 강조하는 내용을 담은 논문입니다.\n다음 학기에 진행될 프로젝트(한화생명, 하나증권 등)에서 LLM 기반 에이전트 시스템을 기획하거나 검증할 때, 이런 risk 평가 관점은 참고할 만한 접근이라고 생각되어 발표 논문으로 선정하였습니다",
    "url": "https://openreview.net/forum?id=frPFuji3Hz&noteId=w7sDUtTtQU"
  },
  {
    "date": "2025년 07월 30일",
    "title": "LLM Economist: Large Population Models and Mechanism Design in Multi-Agent Generative Simulacra",
    "presenter": "Hoyoung Lee",
    "reason": "이 논문은 LLM agent를 활용하여 복잡한 경제 정책을 설계하고 평가하는 'LLM Economist' 프레임워크를 제시합니다. 이 시스템은 미국 인구조사 데이터에 기반한 다양한 노동자 에이전트들이 각자의 효용을 극대화하고, 상위의 계획가 에이전트가 사회 전체의 후생을 목표로 최적의 세금 정책을 찾아가는 2단계 시뮬레이션 구조를 가집니다. 연구 결과, 이 프레임워크는 기존 이론적 해법에 근접하거나 더 나은 사회 후생을 달성하는 정책을 발견했으며, 특히 에이전트들이 투표하는 민주적 절차를 도입했을 때 결과가 더욱 향상되었습니다. 결과적으로 이 연구는 LLM 에이전트가 복잡한 경제 시스템을 시뮬레이션하는 강력한 테스트베드로서 현실에 적용하기 전 정책을 안전하게 실험하고 평가할 수 있는 가능성을 보여줍니다. ",
    "url": "https://arxiv.org/pdf/2507.15815"
  },
  {
    "date": "2025년 07월 22일",
    "title": "Time-VLM: Exploring Multimodal Vision-Language Models for Augmented Time Series Forecasting",
    "presenter": "Juchan Kim",
    "reason": "근 1~2년 사이에 시계열 + LLM 컨셉이 쏟아지고 있는데, 크게 지적받는 부분이 modality gap과 textual representation이 동적인 상황에서 adaptation 되기에는 상당히 제약이 많단 점입니다.\n이 논문은 이를 해결하기 위해 단순한 텍스트 정보가 아니라 VLM을 사용합니다. 이를 통해 시계열로부터 각각 vision/text representation을 얻어내고 동시에 시계열 기반의 representation과 잘 fusion한 연구입니다. \n실험도 few shot / zero shot forecasting 관점에서도 좋은 성능을 보였으며, 일반적인 time-series forecasting task에서도 타 모델들 대비 더 괜찮은 성능을 보일 수도 있었다고 합니다. \nhttps://arxiv.org/abs/2310.01728 대비 모델 파라미터 수도 작아서 실험 확인도 해볼 수 있을 것 같고(논문에서는 A6000 사용), 시계열 예측 및 파운데이션 모델 관점에서 해볼만한 얘기들이 많은 것 같아 선정하게 되었습니다.",
    "url": "https://arxiv.org/pdf/2502.04395"
  },
  {
    "date": "2025년 07월 08일",
    "title": "Roll the dice & look before you leap: Going beyond the creative limits of next-token prediction",
    "presenter": "Inwoo Tae",
    "reason": "본 연구는 이번 ICML 2025에서 oral로 채택된 연구로써, 현재 언어 모델의 창의적 한계를 정량적으로 측정하고 이를 극복하기 위한 multi-token prediction 접근법을 제안하였습니다. 전통적인 next-token prediction의 한계는 한 토큰씩 순차적으로 예측하는 근시안적 접근으로 인해 창의적이고 다양한 출력 생성에 실패하며, 훈련 데이터의 과도한 memorization에 의존한다는 점이었습니다. 논문에서는 실제 창의적 과제를 추상화한 네 가지 알고리즘적 과제를 설계하고, 이를 통해 창의성을 문법적으로 올바르면서도 훈련 데이터에 없는 새로운 출력의 비율로 정의하여 정량화하는 과정을 보여줍니다.\n언어 모델의 창의성이라는 측정하기 어려운 개념을 최소한의 알고리즘적 과제로 추상화하여 체계적으로 분석한다는 접근이 흥미로웠고, 특히 입력 레이어에 노이즈를 주입하는 seed-conditioning이라는 새로운 방법론을 통해 출력의 다양성을 확보한다는 아이디어가 인상적이었습니다. 결과적으로, 논문에서는 teacherless training과 discrete diffusion이라는 multi-token prediction 방법들이 기존 next-token prediction 대비 창의성 점수에서 현저한 개선을 보였으며, seed-conditioning이 모델의 일관성을 해치지 않으면서도 다양성을 효과적으로 증진시킴을 실험 결과를 통해 보여줍니다.",
    "url": "https://arxiv.org/abs/2504.15266"
  },
  {
    "date": "2025년 07월 02일",
    "title": "Latent Variable Estimation in Bayesian Black-Litterman Models",
    "presenter": "Sangjin Jin",
    "reason": "본 연구는 이번 ICML 2025에서 공개된 연구로써, Black-Litterman 포트폴리오 모델에서 투자자 뷰를 latent variable로 취급하여 데이터로부터 학습하는 베이지안 접근법을 제안하였습니다. 전통적인 블랙리터만 모델의 한계는 투자자의 뷰와 불확실성을 주관적으로 설정하고, 이것이 파라미터 추정과 최적화로 이어지기 때문에 오차가 발생할 수 있다는 점이었습니다. 논문에서는 블랙리터만 네트워크 안에서 발생하는 수익률 파라미터 θ와 투자자의 뷰에 대하여 두개의 인과 관계를 정의하고, 이를 활용한 Shared-latent parametrization 모델과 Feature-influence views 모델을 제시합니다.\n블랙-리터만 모델에 대해 보다 자세히 공부해보고자 본 논문을 고른 것도 있고, 투자자의 뷰라는 것을 생성하는 과정에서 의 한계를 bayesian inference로 해결한다는 컨셉이 흥미로웠던 것 같습니다. 결과적으로, 논문에서는 마켓 데이터와 자산 특성(indicators)들을 가지고 통합적인 베이지안 네트워크를 통해 파라미터들을 추정한후, 샤프지수 최대화 문제를 풀어냄으로써 샤프지수와 턴오버 개선 측면에서 효과적이었음을 실증적인 분석을 통해 입증합니다.",
    "url": "https://arxiv.org/abs/2505.02185"
  },
  {
    "date": "2025년 06월 10일",
    "title": "LLM-ESR: Large Language Models Enhancement for Long-tailed Sequential Recommendation",
    "presenter": "Junhyuk Seo",
    "reason": "NeurIPS 2024 spotlight를 받은 논문으로, 추천 시스템에서 대표적으로 어려운 문제인 롱테일 사용자 및 아이템에 대한 성능 저하를 해결하고자, LLM 에서 얻은 의미 기반 임베딩(semantic embedding)과 전통적인 행동 기반 임베딩(collaborative signals)을 통합한 Dual-View Framework를 제안합니다.첫 번째 뷰는 LLM을 통해 사용자 및 아이템 설명에서 추출한 의미 정보를, 두 번째 뷰는 사용자-아이템 상호작용 데이터에서 얻은 행동 정보를 활용하며, 두 표현을 효과적으로 결합해 보다 일반화된 추천 성능을 도출합니다. 특히, 데이터가 부족한 롱테일 사용자에 대해서는 Retrieval-Augmented Self-Distillation (RA-SD) 기법을 도입해, 유사한 행동 패턴을 가진 다른 사용자 데이터를 참조하며 의미 표현을 강화합니다.이 논문을 금융 도메인에 적용할 수 있을지에 대해 고민하며 발표 논문으로 선정했습니다. 예를 들어, LLM 기반의 금융 상품 검색 또는 추천 시스템에서도 시가총액이 큰 대형주나 유명 ETF에 추천이 편향되는 현상은 일종의 롱테일 문제로 볼 수 있습니다.물론 금융 분야에서는 개인의 거래 데이터를 확보하기 어렵고, 사용자 행동 데이터가 제한적이지만, LLM의 풍부한 의미 추론 능력을 바탕으로 보다 다양한 금융 상품을 의미적으로 탐색하고 추천할 수 있는 가능성이 있지 않을까?라고 생각하며 이 논문을 선정하게 되었습니다\n\n",
    "url": "https://arxiv.org/abs/2405.20646"
  },
  {
    "date": "2025년 05월 27일",
    "title": "Language Models Still Struggle to Zero-shot Reason about Time Series",
    "presenter": "Suhwan Park",
    "reason": "EMNLP 2024년 논문으로 현재의 LLM이 시계열 데이터에 대해 진정한 추론(reasoning) 능력을 가지고 있는지를 검증하고자 한 연구입니다. 최근 LLM을 활용해 시계열 데이터를 텍스트처럼 처리하고 예측하는 연구들이 나왔지만, 단순히 데이터를 예측한다고 해서 이해나 추론을 한다고 말할 수 없음을 지적합니다.세 가지 과제 (원인 추론, 질문 응답, 문맥 기반 예측)로 나누어 LLM의 능력을 검증하여 예측 ≠ 추론이라는 점을 강조하며, LLM이 시계열을 이해할 수 있는지를 정량적으로 평가하기 위해 새로운 벤치마크와 데이터셋을 제시합니다.앞으로의 LLM 연구가 단순 예측을 넘어서, 시계열 추론 능력 향상을 중심으로 나아갈 필요가 있음을 강조합니다. 최근에는 이를 극복하기 위한 방향으로 Time-aware LLM, 멀티모달 reasoning과 같은 연구들도 제안되고 있어, 시간이 된다면 관련 연구들 간단히 소개드리려 합니다.",
    "url": "https://arxiv.org/abs/2404.11757"
  },
  {
    "date": "2025년 05월 20일",
    "title": "Learning To Solve Differential Equation Constrained Optimization Problems",
    "presenter": "Junhyeong Lee",
    "reason": "이 논문은 이번 ICLR 2025 Spotlight를 받은 논문입니다.최적화 문제 중에는 state가 ODE/SDE와 같은 differential equation에 따라 다이나믹하게 변화하는 시스템을 다루는 문제들도 존재합니다. 이런 differential equation이 constraint에 들어가게 되는 경우 일반적으로 np-hard문제이며, 기존 수치해석적인 방법론으로도 확장성과 정밀도면에서 한계점이 존재합니다. 이 논문에서는 DE-OP framework를 제안하여 proxy optimizer로 problem parameter로부터 decision variable를 얻도록 하고, Neural-DE 모델로 differential equation의 해를 neural net으로 근사하도록 학습합니다.이 과정에서 Lagrangian dual을 통해 steady-state와 dynamic-state constraint를 동시에 완화하여 loss에 반영하도록 디자인해서 기존의 DFL 연구들 처럼 DE-OP 전체를 gradient 기반으로 학습가능하게 합니다.기존 DFL 연구들은 보통 constraint가 정적인 세팅에서 많이 이루어졌는데, 이런 다이나믹을 제약으로가지는 최적화 문제에 대한 접근법이 흥미로워서 선정해봤습니다.",
    "url": "https://arxiv.org/abs/2410.01786"
  },
  {
    "date": "2025년 05월 13일",
    "title": "Do I Know This Entity? Knowledge Awareness and Hallucinations in Language Models",
    "presenter": "Hoyoung Lee",
    "reason": "최근 LLM의 내부 행동을 해석하고 이해하려는 연구가 활발히 진행되는 가운데 본 논문은 LLM에서 발생하는 고질적인 문제인 할루시네이션의 근본 메커니즘을 파악하고자 합니다. 핵심적으로, LLM이 영화, 운동선수와 같은 특정 엔티티에 대한 정보를 실제로 기억하고 있는지 여부를 내부적으로 인식하는 과정이 할루시네이션 발생에 중요한 역할을 한다는 점을 밝혀냈습니다. 이를 규명하기 위해 저자들은 희소 오토인코더라는 방법론을 사용하여 모델 내부 표현 공간에서 엔티티에 대한 인지 여부를 나타내는 선형 방향, 즉 '엔티티 인식 방향'을 포착해냈습니다. 더 나아가, 이 연구는 해당 방향을 인위적으로 조작함으로써 모델이 알지 못하는 엔티티에 대해 답변을 거부하도록 유도하거나, 반대로 환각을 생성하도록 행동을 제어할 수 있음을 실험적으로 보여줍니다. 이처럼 모델의 할루시네이션을 내부 메커니즘 수준에서 이해하고 제어할 수 있는 가능성을 제시한다는 점이 흥미로웠고, 금융에서는 정보의 정확성이 매우 중요하기 때문에 LLM을 활용하고자 할 때 할루시네이션은 반드시 해결해야 할 핵심 과제라고 생각해 선정하게 되었습니다.",
    "url": "https://openreview.net/forum?id=WCRQFlji2q"
  },
  {
    "date": "2025년 04월 15일",
    "title": "Geodesic Flow Kernels for Semi-Supervised Learning on Mixed-Variable Tabular Dataset",
    "presenter": "Yongjae Lee",
    "reason": "황윤태 박사가 주도하여 진행했던 tabular data 관련 연구이고 올해 AAAI에 발표되었습니다. 황박사 덕분에 tabular data에 대해서 같이 고민을 해보게 되었고, 그 과정에서 tabular data가 다른 이미지나 텍스트에 비해 가지는 특성을 크게 세 가지로 잡아봤습니다. 1. categorical과 numerical이라는 서로 다른 type의 variable들이 섞여있다. 특히 categorical variable 중에서도 ordering이 되지 않는 변수들은 numerical과 특성이 매우 다릅니다. 2. 모든 feature 값이 같더라도 단 한두개 feature의 변화만으로 그 의미가 완전히 달라질 수 있다. 3. 데이터의 row와 column의 순서가 의미가 없다 (시계열 제외). 즉, row와 column의 순서를 바꾸더라도 데이터의 의미가 전혀 달라지지 않는다. 그래서 저희 연구에서는 이 세 가지를 지적을 하고 이 부분을 다루기 위해서 노력을 해보았습니다. 이러한 관점을 연구실 학생들에게도 제대로 소개를 해주고 싶어서 이 논문으로 골랐습니다.",
    "url": "https://arxiv.org/abs/2412.12864"
  },
  {
    "date": "2025년 04월 08일",
    "title": "Fair Clustering in the Sliding Window Model",
    "presenter": "Juchan Kim",
    "reason": "일반적인 클러스터링 알고리즘은 data point들의 중심점을 잡아서 몇 가지 군집으로 묶는 과정을 거칩니다. 그런데 이 부분에서, 크게 두 가지의 문제점이 발생할 수 있는데요, 첫 번째는 fairness issue로, datapoint별로 정해진 subgroup이 있다고 가정한다면 이를 일반적인 클러스터링 알고리즘으로 묶었을 때 특정 클러스터에 어느 subgroup이 속해있지 않은 상황이 생기게 되는 상황이 생기는 경우가 생길 수 있습니다. 이렇게 원치 않는 bias를 학습하지 않도록 하기 위해 fair clustering 같은 방법을 통해 subgroup별 비율을 유지함으로써 성능을 약간씩 trade-off 하는 경우가 있습니다. 두 번째 문제는 좀 더 실무적인 부분인데, 개인 정보를 보유할 수 있는 기업들은 대부분 개인 정보 보호법 같은 법률 때문에 이를 일정 기간 이상 보관하지 못하고 폐기하게 되어있습니다. 즉, 이러한 민감한 정보를 다루기 위해서는 필연적으로 datapoint 정보들이 시간이 지남에 따라 바뀌고 이를 반영해야 하는 상황이 됩니다. 본 논문에서는 이를 sliding window 내에서의 모델을 구축하는 것으로 일컫습니다.이 논문에서 주요한 기여점은 말씀드린 두 가지 문제점을 해결하기 위한 알고리즘을 제시한 것에 있습니다. 특히, 전체 데이터 샘플이 아닌 task의 fariness 제약 조건을 근사하는 subset인 coreset의 존재성 및 이를 얻어내는 알고리즘을 통해서 최종적으로 cost/time 모두 기존 알고리즘 대비 좋은 실험 결과를 얻었고, 이를 통해 해당 방법의 정당성을 입증했다고 보시면 될 것 같습니다.",
    "url": "https://openreview.net/forum?id=VGQugiuCQs"
  },
  {
    "date": "2025년 04월 01일",
    "title": "Has the Deep Neural Network learned the Stochastic Process? An Evaluation Viewpoint",
    "presenter": "Inwoo Tae",
    "reason": "이번 논문은 복잡하고 확률적으로 예측하는 딥러닝 모델이 단순히 관측된 결과에만 정합되는 것이 아니라, 해당 시스템의 본질적인 확률적 과정을 학습했는지를 평가할 수 있는 지 새로운 기준을 제시했습니다. 기존의 평가지표들(AUC-PR, MSE 등)은 하나의 결과(Observed Ground Truth)에 대한 정합도만 측정하기 때문에, 모델이 실제로 확률적 구조를 이해했는지 판단하기 어렵습니다. 저자들은 이러한 한계를 극복하기 위해 Fidelity to Stochastic Process(F2SP)라는 새로운 평가 기준을 도입하고, 이를 측정할 수 있는 지표로 Expected Calibration Error(ECE)를 제안했습니다. F2SP는 동일한 초기 조건에서 발생할 수 있는 모든 가능한 결과들의 통계적 특성, 즉 Statistic Ground Truth에 대한 모델의 정합도를 평가하는 기준입니다. 실제 상황에서는 이 통계적 특성이 직접 관측되지 않기 때문에, 저자들은 ECE가 관측된 단일 결과만으로도 F2SP를 평가할 수 있는 유일한 지표임을 이론적으로 정립했습니다. 실험 결과에 따르면, ECE는 훈련과 테스트 시점의 stochastic level이 일치할 때 안정적인 값을 유지하며, 모델이 해당 확률적 과정을 잘 학습했는지를 효과적으로 반영하는 반면, AUC-PR과 MSE는 확률적 변동성에 따라 성능이 크게 흔들리는 것을 확인 할 수 있습니다.",
    "url": "https://openreview.net/pdf?id=2U8owdruSQ"
  },
  {
    "date": "2025년 03월 25일",
    "title": "Group-robust Sample Reweighting for Subpopulation Shifts via Influence Functions",
    "presenter": "Kangmin Kim",
    "reason": "Group Robustness 관련 논문을 찾다가 발견한 논문이고, ICLR 2025에 accept 되었습니다. 이전에 소개했던 Group DRO는 loss를 업데이트할 때 각 그룹 별 가중치를 동시에 업데이트하는 방식을 사용하고 있습니다. 이 논문에서 소개하는 GSR(Group-robust Sample Reweighting) 방법은 two-stage로 이루어져있습니다. 첫번째 stage에서는 기존의 ERM방식으로 representation과 classifier를 학습합니다. 두번째 stage에서는 label이 있는 training sample별 hessian을 활용해 가중치를 지속적으로 reweighting하고, representation은 고정해놓고, classifier를 재학습하는 방식으로이루어져있습니다.실험에서도 Group DRO를 포함한 여러 Baseline과의 비교를햇을 전반적으로 더 나은 성능을 보여줬습니다. 그리고 major group과 minor group의 sample weights distribution에도 차이가 있음을 보여줬습니다. 또한 이를 통해 group robustness와 effectiveness를 챙겼으며, label noise가 있어도 robust한 모습을 보여줬습니다.",
    "url": "https://arxiv.org/abs/2503.07315"
  },
  {
    "date": "2025년 03월 18일",
    "title": "BPQP: A Differentiable Convex Optimization Framework for Efficient End-to-End Learning",
    "presenter": "Sangjin Jin",
    "reason": "본 논문에서는 최적화 문제에 대한 End-to-End learning을 보다 효율적으로 수행하는 \"Backward Pass as a Quadratic Programming\"(BPQP)라는 프레임워크를 소개합니다. 최적화 문제를 E2E로 학습하려면 역전파 과정에서 최적화 문제를 미분해야하는데, 기존 방법들은 최적화 문제의 해를 미분 가능하게 만들기 위해 KKT system을 통한 Implict Differentitation를 통해 이를 해결하였습니다. 그러나, 기존 방법들은 최적해를 구하는 과정에서 Jacobian 행렬의 역행렬을 계산하거나 linear system을 푸는 연산이 요구되어, 큰 스케일에서는 효율적이지 못하다는 문제점이 존재하였습니다. BPQP는 KKT system을 Quadratic Programming(QP) 문제로 변환하여 보다 쉽게 풀어냄으로써 학습하는 방법을 제시합니다. 이 과정을 통해 연산량을 확연하게 줄이고, 역전파 과정에서 QP를 풀기위한 first-order solver 선택에 대해 확장 가능성을 높였음을 밝혔습니다.실험 결과, 기존 방법들(OptNet, CVXPY 등)에 비해 최대 13배나 효율적인 연산을 보였으며, 대규모 LP, QP 문제들 뿐만 아니라 포트폴리오 MVO에 대한 실험도 포함하고 있어, 관심 있게 볼 수 있을 것 같습니다. 마이크로소프트의 핀테크 연구원들이 작성한 논문이기도 하고, NeurIPS 24'에서 spotlight paper에 선정된 논문인만큼 딥러닝이 최적화 문제를 어떻게 해결하는지에 대해 자세히 살펴볼 수 있을 것 같아 함께 읽어보고자 합니다!\n\n",
    "url": "https://openreview.net/forum?id=VKKY3Uv7vi&referrer=%5Bthe%20profile%20of%20Jiang%20Bian%5D(%2Fprofile%3Fid%3D~Jiang_Bian1)"
  },
  {
    "date": "2025년 02월 18일",
    "title": "Self-Rewarding Language Models",
    "presenter": "Junhyuk Seo",
    "reason": "ICML 2024에 억셉된 논문으로, 최근 LLM 관련 연구에 관심을 가지고 살펴보며 접하게 되었습니다. 특히, 랩실에서 AICP 관련 이야기를 하며 LLM에 더욱 주목하게 되었고 내용이 흥미로워 선정하게 되었습니다.기존 LLM 학습 방식인 Reinforcement Learning from Human Feedback(RLHF), Direct Preference Optimization(DPO), Proximal Policy Optimization(PPO)과 달리, 이 논문에서는 모델이 외부 또는 인간의 피드백 없이 스스로 보상을 생성하는 Self-Rewarding 방식을 제안합니다. Self-Rewarding Language Models에서의 접근법은 Iterative DPO 훈련을 통해 모델이 지침을 따르는 능력과 보상 모델을 개선하는 능력을 동시에 향상시키는 과정으로 이루어집니다. 기존의 보상 모델이 외부에서 제공되는 것과 달리, 이 접근법에서는 모델이 훈련 도중에 스스로 보상을 생성하고 이를 바탕으로 성능을 점진적으로 향상시킬 수 있습니다.실험에서 Llama 2 70B 모델을 대상으로 세 번의 Iterative DPO 훈련을 수행한 결과, Self-Rewarding 접근법을 적용한 모델이 AlpacaEval 2.0 리더보드에서 Claude 2, Gemini Pro, GPT-4 0613 등 기존의 여러 시스템을 능가하는 성능을 보였습니다. 이는 모델이 인간의 피드백 없이도 스스로 성능을 지속적으로 향상시킬 수 있는 가능성을 보여줍니다.저는 개인적으로 논문을 읽으며 이러한 접근법이 신선하다고 생각했지만, 앞으로 인간의 개입 없이도 지속적으로 활용될 수 있을지에 대한 의문이 남았습니다. 특히, 모델이 자기 평가를 기반으로 학습할 경우 발생할 수 있는 편향성과 안정성 문제는 추가 연구가 필요한 부분입니다. 논문에서도 이러한 한계를 인정하며, 안전성과 지속 가능성에 대한 연구 방향을 제시하고 있습니다.",
    "url": "https://arxiv.org/pdf/2401.10020"
  },
  {
    "date": "2025년 02월 18일",
    "title": "Improving Portfolio Performance via Natural Language Processing Methods",
    "presenter": "Suhwan Park",
    "reason": "2022 JFDS 논문입니다. 자연어 처리를 활용하여 포트폴리오 최적화를 개선하는 방법을 연구한 것으로, 특히 소셜 미디어 데이터(Twitter)와 NLP 기술을 결합하여 주식 포트폴리오를 구성하는 방식을 제안합니다. 기존 Markowitz 평균-분산 최적화(MVO) 모델의 한계를 보완하기 위해 텍스트 기반 공분산 행렬을 도입하며, 전통적인 공분산 행렬(과거 수익률 기반)과 문서 임베딩 간 유사도를 활용한 공분산 행렬을 선형 결합 형태로 혼합하는 방식을 제안합니다.\n실험 결과, 텍스트 임베딩을 활용한 포트폴리오 최적화 기법이 기존 방법(Markowitz, Ledoit-Wolf Shrinkage, Black-Litterman 등)과 비교하여 더 높은 샤프비율을 기록했으며, 특히 COVID-19와 같은 시장 충격 상황에서 더 효과적으로 대응할 수 있음을 보였습니다. 논문에서 제시된 방법론이 비교적 너무 간략하게 서술된 것 같아, 논문에서 활용한 벤치마크 모델(Ledoit-Wolf Shrinkage, Oracle Estimator Shrinkage, Black-Litterman Portfolio, Enhanced Portfolio Optimization 등)이 각각 어떻게 활용되었는지 추가로 간단하게 리뷰해보려 합니다. 텍스트 임베딩을 포트폴리오 최적화에 반영한 간단한 연구로 어렵지 않게 읽으실 수 있을 것 같습니다!",
    "url": "https://www.pm-research.com/content/iijjfds/4/2/37"
  },
  {
    "date": "2025년 02월 04일",
    "title": "The REVERSAL CURES: LLMs Trained on “A is B” Fail to Learn “B is A”",
    "presenter": "Junhyeong Lee",
    "reason": "ICLR'24에 억셉된 논문입니다. 사실 저는 LLM류 연구들에 크게 흥미를 느낀적이 별로 없어서 논문 편식(?)을 했었는데, 최근 Deepseek의 파장도 그렇고 조금씩 팔로업은 하는게 나을까 싶어서 LLM 관련 논문을 선정해봤습니다 ㅎㅎ...제가 하고자하는 DFL과 같은 연구들은 AI를 일종의 도구로 이용하여 문제를 해결하기 위한 연구라고 생각이듭니다. 그러나 제가 지난 저널클럽때 발표했던 vision연구나, 이번에 선정한 논문과 같은 연구에서는 AI를 일종의 인간과 같은 수준 혹은 그 이상의 지능을 가진 어떠한 'object' 처럼 다루고자 하는게 아닐까 싶은 생각도 듭니다. 그래서 이런류의 연구에서는 인간의 인지능력이나 사고능력으로는 너무나도 쉽게 가능한 일들이 왜 기계에서는 되지 않는가? 어떻게 가능하게 할 수 있는가? 에 대한 질문들을 많이 던지는 것 같습니다.이번 논문에서도 reversal curse라는 llm 모델의 일반화 성능에 대한 문제점을 이야기합니다. 인간이라면, 보편적 논리구조를 가진 시스템하에 작동한다면, A = B 가 참이라면, 당연히 B = A도 참이라는 답을 할 수 있어야 합니다. 그러나 이상하게도 LLMs은 이러한 부분을 제대로 답하지 못하는 현상이 발생한다고 합니다. 이러한 현상이 실제로 얼마나 발생하는지, 왜 발생하는지에 대한 물음에 실험적으로 답을 하고자 한 논문입니다. 저널클럽에서 다양한 이야기 나눌 수 있으면 좋을 것 같습니다!",
    "url": "https://arxiv.org/pdf/2309.12288#page=17.54"
  },
  {
    "date": "2025년 01월 21일",
    "title": "Performance Attribution for Portfolio Constraints",
    "presenter": "Yongjae Lee",
    "reason": "Andrew Lo 교수님 논문으로 몇 주 전에 Management Science에 나왔습니다. Portfolio performance를 mvo, constraint, information 이렇게 세 가지로 decompose하여 살펴볼 수 있다는 내용입니다. 내용이 흥미로워 보이기도 하고, 저희 여러 연구에도 응용해볼 여지가 있을 듯 하여 선정했습니다. 수식을 일일이 다 디테일하게 보기보다는 전체적으로 아이디어를 개념적으로 살펴볼 수 있도록 해보겠습니다. (edited) ",
    "url": "https://doi.org/10.1287/mnsc.2024.05365"
  },
  {
    "date": "2025년 01월 21일",
    "title": "Newton Losses: Using Curvature Information for Learning with Differentiable Algorithms",
    "presenter": "Juchan Kim",
    "reason": "전통적인 최적화 분야에서의 2nd order method 를 딥러닝에서 사용해보기 위한 연구입니다. 이러기 어려운 가장 큰 이유는 parameter에 대한 Hessian의 inverse를 구하기 위한 computational complexity가 너무 높다는 점인데요, 이를 해결하기 위해, 본 논문에서는 일반적으로 사용하는 loss를 두가지로 구분하여 하나는 input -> output으로 내뱉는 모델 관점에서의 update rule과 하나는 일반적인 loss 관점(e.g. MSE)에서의 parameter update rule을 따로 사용하여 최종적인 update rule을 구성하게 됩니다. 최적화 논문 치고 필요한 선행지식도 그렇게 크지 않은 것 같고, 아이디어도 괜찮은 것 같아서 재미있게 읽을 수 있으실 것 같아 선정하게 되었습니다. ",
    "url": "https://arxiv.org/pdf/2410.19055"
  },
  {
    "date": "2025년 01월 07일",
    "title": "Long-range Brain Graph Transformer",
    "presenter": "Inwoo Tae",
    "reason": "그래프의 intra한 특성과 inter한 특성을 동시에 반영할 수 있는 논문 중 해당 논문이 그 내용을 채울 수 있을 것 같아서 선택했습니다. 기존 연구에서는 뇌 네트워크 분석에서 short-term 의존성에 주로 초점을 맞췄으나, long-term 의존성을 고려하지 않아 뇌 전체의 통합적 이해에 한계가 있었습니다. 그러나 해당 논문은 이러한 점을 해결하기 위해 long-term에 대한 의존성을 효과적으로 포착하는 ALTER(Adaptive Long-range aware TransformER)라는 새로운 모델을 소개합니다. ALTER는 correlation 기반의 biased random walk를 통해 뇌의 여러 관심 영역(ROIs) 간 통신 강도를 모델링하고, 이를 Transformer에 통합해 short-term과 long-term 의존성을 동시에 학습합니다. ALTER는 자폐 스펙트럼 장애(ASD)와 알츠하이머병(AD) 데이터셋에서 기존 모델들을 능가하는 성과를 보였습니다. 이 모델의 핵심인 ALGA 전략은 correlation이 높은 ROIs를 더 자주 선택하도록 설계되었습니다. 편하게 읽으시고 다양한 질문 던져주시면 감사하겠습니다.",
    "url": "https://arxiv.org/pdf/2501.01100"
  },
  {
    "date": "2025년 01월 07일",
    "title": "Distributionally Robust Neural Networks for Group Shifts: On the Importance of Regularization for Worst-Case Generalization",
    "presenter": "Kangmin Kim",
    "reason": "이번 저널클럽에 소개할 논문은 Distributionally Robust Optimization(DRO)의 한 방법론인 Group DRO를 소개하는 논문이고, ICLR 2020 Poster Session에 억셉 되었습니다. 데이터를 사전에 정의된 그룹으로 나누고, 최악 그룹의 손실을 최소화하도록 모델을 학습시킴으로써, 데이터 편향이나 허구적인 상관관계로 인한 성능 저하를 방지합니다. train, test distribution이 다를 때 에 많이 사용되는 Importance Weighting같은 경우에는 training frequency라는 고정된 숫자를 사용해 loss의 weighted sum이 가장 낮아지도록 설계되어있지만, 논문에서 제시하는 방법론은 Gradient Update 과정에서 지속적으로 Importance를 업데이트해 Worst Group에서의 성능을 일정 부분 보장합니다.",
    "url": "https://arxiv.org/abs/1911.08731"
  },
  {
    "date": "2024년 12월 11일",
    "title": "Large Langugae Models as Optimizers",
    "presenter": "Sangjin Jin",
    "reason": "위 논문은 구글 딥마인드의 Large Language Models as Optimizers 라는 논문으로, LLM을 이용해 최적화 문제를 푸는 Optimization by PROmpting (OPRO) 프레임워크를 제시하고 있습니다. 기존 최적화 방법론들이 미분 가능성에 의존하여 문제를 해결해나갔다면, 본 연구에서는 이를 언어 모델이 가진 추론 능력으로 해결하는 과정을 제시함으로써 더욱 복잡한 문제에 도전하고자 하는 취지를 지니고 있습니다. OPRO는 크게 세 가지 과정으로 작동합니다: 1) Meta-Prompt: 최적화 문제를 언어로 표현하고 이전에 생성한 솔루션에 대한 스코어를 보유함, 2) LLM as Optimizer: 주어진 Meta-Prompt를 기반으로 하여 스코어를 향상시키는 방향으로 새로운 솔루션 생성, 3) Objective Function Evaluator: LLM이 생성한 솔루션을 평가하고 다음 스텝에 반영. 위 과정들이 일종의 강화학습처럼 반복적으로 수행되며 최적화 문제에 대한 해를 찾아나갑니다.OPRO를 통한 실험은 수학적 추론 문제(선형회귀, 외판원 문제)와 프롬프트 최적화를 대상으로 진행되었습니다. 외판원 문제의 경우, 작은 n에서는 성공적으로 최적 경로를 찾았으며, n이 50까지 커진 상황에서도 기존 알고리즘(NN, FI)들에 근접한 결과를 보여주었습니다. 또 다른 태스크인 프롬프트 최적화는 LLM이 프롬프트에 따라 민감하게 반응한다는 점으로부터 착안하여, LLM이 어려운 추론 문제들을 해결할 수 있도록 프롬프트를 개선하는 내용입니다. 프롬프트의 민감성과 프롬프트 조합의 다양성에도 불구하고 OPRO는 성능 개선을 이끌어냈으며, 이를 다른 데이터에도 일반화시킬 수 있음을 입증하였습니다.위 논문은 ICLR'24에서 소개되었으며, 이전 발표에서 다뤄주신 ICL이나 교수님께서 언급하신 '최적화를 위한 대형모델'에 대한 연구가 있는지 살펴보던 와중 찾게된 논문입니다. 논문의 분량은 길지만, 방법론 자체는 복잡하지 않으며 LLM을 최적화의 solver로서 사용하고자 할때, 어떤 방향으로 사용해야 할지에 대한 가이드라인을 제공해줄 수 있는 연구라고 생각되어 가지고 왔습니다.\n\n",
    "url": "https://arxiv.org/abs/2309.03409"
  },
  {
    "date": "2024년 12월 03일",
    "title": "Deep Learning and Time Series-to-Image Encoding for Financial Forecasting",
    "presenter": "Junhyuk Seo",
    "reason": "기존 금융 시계열 예측에서는 많은 fluctuation이 존재해서 CNN과 같은 모델들은 많은 어려움이 있습니다.이 논문에서는 이를 해결해보며, 금융 시장 예측을 위해서 시계열 데이터를 이미지로 변환하고, 이를 심층 학습 모델에 적용하는 접근 방식을 제시합니다.이를 위해 시계열을 2D 이미지로 변환하는 방법 중 하나인 GAF로 변환하여 이미지 형태로 표현하고, 이를 CNN에 입력하여 사용합니다.이 연구에서는 미국 S&P 500 지수 선물 데이터를 활용하여 GAF 이미지를 생성하고, 다양한 해상도의 이미지를 CNN에 입력하는 다중 해상도 접근 방식을 도입했습니다.이를 통해 단일 관측치에 대해 다양한 시간 간격을 분석할 수 있게 되었습니다.성능 평가를 위해서는 간단한 트레이딩 시스템으로 예측 결과를 활용했습니다.결과적으로, 제안된 방법은 동일한 기간 동안 우수한 수익을 제공하는 매수 후 보유(Buy & Hold) 전략을 능가하는 성과를 보였고, 시계열 데이터를 이미지로 변환하고 이를 모델에 적용하는 새로운 방법론을 통해 금융 시장 예측의 정확도와 효율성을 높일 수 있음을 확인할 수 있었습니다.\n\n",
    "url": "https://www.iris.unina.it/retrieve/handle/11588/807057/337910/IEEE_CAA_Journal_of_Automatica_Sinica-3.pdf"
  },
  {
    "date": "2024년 11월 05일",
    "title": "Learning from Memory: Non-Parametric Memory Augmented Self-Supervised Learning of Visual Features",
    "presenter": "Junhyeong Lee",
    "reason": "이 논문은 ICML 2024에 억셉된 논문으로, motivation이 나름 흥미롭기도 하고, 이런 류의 논문을 요즘 많이 못읽어봐서 선정해봤습니다.SSL 논문인데, vision task에 적용한 논문 입니다.인간은 처음 겪는 경험에서는 흥분, 놀람 등의 감정을 가지지만, 비슷한 경험이 다시 반복된다면 처음 만큼의 강렬함은 줄어들텐데요, 이런 생각을 바탕으로 memory에 기반한 non-parametric method를 통해 모델을 학습시킨다고 합니다.이를 통해 기존 연구들이 가지고 있던 학습과정에서의 불안정했던 문제들이나, model collapse와 같은 현상을 방지하면서도 효율적으로 학습이 가능해졌다고 주장합니다. 제안한 방법론은 간단해보이지만 효과는 꽤나 훌륭합니다. 실험 위주로 많이 보여주는 논문이라서, 여러 방면에서 살펴보면서 읽어보면 좋을 것 같습니다.",
    "url": "https://arxiv.org/abs/2407.17486"
  },
  {
    "date": "2024년 10월 29일",
    "title": "Efficient Streaming language models with Attention Sinks",
    "presenter": "Suhwan Park",
    "reason": "최근 LLM에 관심이 생겨 관련한 논문을 가져왔습니다. 해당 논문은 ICLR 2024에 accept 되었고, transformer 모델의 어텐션 특성에 대한 연구입니다. structure적인 내용이 적어 어렵지 않게 읽으실 수 있을 것 같습니다!서비스 관점에서 유용한 application을 만들기 위해 LLM은 long sequence generation을 수행할 수 있어야 합니다. 그러나 현재 LLM은 pre-trained 과정에서 설정된 input token length 이상의 sequence를 생성 하는데 어려움을 겪습니다. 따라서 infinite input stream에 대해서 현존 LLM이 대응하기 어렵고 이로인해 서비스의 질이 낮아지게 되는 것을 문제 상황으로 지적합니다.논문에서는 infinite input stream에 대응할 때 두 가지 challenge를 제안합니다.\n• 1) memory usage           LLM은 input 처리 시, attention에 사용되는 key, value를 캐시로 저장하는데 input이 infinite 한 형태라면 cache size가 지속적으로 증가하는 문제가 발생합니다.\n• 2) attention window size           pre-trained 과정에서 설정한 input token length를 attention window라고 부르는데 LLM은 이를 넘어선 input을 받았을 때 performance가 저하됩니다.이에 대한 대표적인 해결법으로는 모든 key, value를 이용하는 것이 아니라 Query의 인접 token 만을 고정된 크기로 이용하는 window attention을 사용하는 것입니다. 하지만 window attention은 input sequence length가 window size를 넘어가는 순간 성능이 크게 저하된다는 단점이 있습니다.논문의 저자들이 실험을 통해 발견한 사항은 다음과 같습니다: attention 연산 과정에서 발생하는 attention score 중 대부분을 초기 몇 개의 token이 차지한다는 점입니다. 이 때문에 input length가 길어지면 초기 token이 제거되는 window attention은 성능이 떨어지게 됩니다. 논문에서는 해결방안으로 이러한 초기 몇 개의 token들을 attention sinks라고 부르며 attention sink들을 유지하면서 최근 몇 개의 token들만 사용하는 StreamingLLM을 제시합니다.",
    "url": "https://arxiv.org/abs/2309.17453"
  },
  {
    "date": "2024년 10월 15일",
    "title": "Enhancing mean–variance portfolio optimization through GANs-based anomaly detection",
    "presenter": "Yongjae Lee",
    "reason": "ICAIF’23에 세영 학생이랑 작성하여 발표했던 GANs기반 anomaly detection 연구를 고려대 김장호 교수님과 함께 확장한 것으로 이번에 ANOR의 Markowitz 교수님 추모 special issue에 실린 논문입니다. 정상적인 시기의 주식 섹터 시계열을 잘라서 GANs로 학습시킴으로써, 학습되지 않은 비정상적인 시기의 시계열을 descriminator가 anomaly로 판별할 수 있도록 한 연구였습니다. 이 논문은 이를 shrinkage estimator와 Gerber statistic에 적용을 했습니다. Anomaly로 판별이 되면 shrinkage와 Gerber를 보다 rough하게 잡아주고요, 그렇지 않은 시기에는 좀 더 tight하게 잡아줌으로써 MVO의 parameter uncertainty에 dynamic하게 대응하기 위한 연구 입니다.",
    "url": "https://link.springer.com/article/10.1007/s10479-024-06293-x"
  },
  {
    "date": "2024년 10월 08일",
    "title": "Portfolio optimization with behavioural preferences and investor memory",
    "presenter": "Juchan Kim",
    "reason": "투자자의 행동을 모델링하기 위해서는 보통 아주 단순한 가정을 하고 시작합니다. 대부분의 경우에는 투자자들은 각각의 utility를 가지고 있고, 각각 이를 maximize 하고자 한다는 간단한 내용인데요, 여기서 utility function을 어떻게 두느냐에 따라서 모델링 방법이 달라진 다는 것이 포인트입니다. 우리가 잘 알고 있는 mean-variance optimization 같은 경우도, 이러한 관점에서는 '일부 투자자들은 mean-variance utility 를 maximize하고자 한다' 라는 가정으로 utility function을 mu, sigma를 고려한 quadratic utility로 둘 수 있는 것이죠.\n이 논문에서는 utility maximization problem에 투자자들의 이전 기간에서의 이익, 손실에 대한 민감도를 고려한 형태를 반영해 multi-stage 에서 투자자의 과거 손실, 이익에 따른 utility function을 새로 제시합니다. 이러한 모형을 Kahneman의 prospect theory 기반의 utility function, mean-variance utility function 등과 같은 다양한 투자자 모델링 기법과 비교하면서 여러가지 insight를 제시합니다. 큰 줄기에서는 내용이 이렇고, 세부적으로 어떤 내용을 제시하는지는 내용이 꽤 있어서 확인하고 싶은 부분에 맞춰서 읽어보시면 될 것 같습니다.",
    "url": "https://www.sciencedirect.com/science/article/abs/pii/S0377221721003799?fr=RR-2&ref=pdf_download&rr=8cc1ec038b39aa65"
  },
  {
    "date": "2024년 09월 30일",
    "title": "Accurate Learning of Graph Representations with Graph Multiset Pooling",
    "presenter": "Inwoo Tae",
    "reason": "금융위원회에서 진행하는 프로젝트에서 그래프를 활용해서 데이터셋을 표현하는데, 각 그려지는 그래프의 크기가 클 것으로 예상해서 이를 Pooling할 수 있는 방안이 뭐가 있는지 찾아보던 중에 해당 논문을 찾아서 올려드립니다. 해당 논문은 ICLR 2021에 accpet되었습니다. KAIST 황성주 교수님 연구실에서 작성한 논문으로, multiset에서 graph multiset pooling을 사용하여 유사한 노드들의 대표 노드를 집계하여 구조적인 정보를 잃지 않고 graph를 pooling하는 방식을 소개합니다. 내용 자체가 어렵지 않고 전체적인 graph pooling concept등을 쉽게 표현하고 있어서 재미있게 읽으실 수 있을 것 같습니다.",
    "url": "https://arxiv.org/abs/2102.11533"
  },
  {
    "date": "2024년 09월 24일",
    "title": "Is Momentum Really Momentum?",
    "presenter": "Kangmin Kim",
    "reason": "이번에는 finance논문을 들고왔는데요, 제가 소개할 논문은 2012년 Journal of Fianncial Economics에 accepted된 https://www.sciencedirect.com/science/article/pii/S0304405X11001152이라는 논문입니다. 다들 아시겠지만 momentum은 최근 가격이 상승했던 주식들이 더 상승할 것이라는 생각에서 비롯된 투자전략인데요, 논문에서는 12개월에서 7개월 전의 수익률(중기 모멘텀)이 6개월에서 2개월 전의 수익률(단기 모멘텀)보다 향후 수익을 예측하는 데 더 강력하다는 점을 얘기하고 있습니다. 또한 주식 시장의 유동성이 높고, 대형주에서 중기 모멘텀 전략이 특히 효과적임을 강조하는데요, 중기 모멘텀을 기반으로 한 투자 전략이 장기적으로 더 높은 수익을 창출할 수 있다고 합니다. 10년이 넘은 논문이라 실제 적용할 수 있을지는 모르겠지만 momentum에대한 새로운 시각을 제시하는 것이 흥미로워서 선정해보았습니다.",
    "url": "https://www.sciencedirect.com/science/article/pii/S0304405X11001152"
  },
  {
    "date": "2024년 08월 22일",
    "title": "Deep-learning models for forecasting financial risk premia and their interpretations",
    "presenter": "Junhyeong Lee",
    "reason": "MIT Sloan의 https://alo.mit.edu/ 교수님의 연구들을 살펴보다가 발견한 논문입니다. 저희 연구실과 연구하는 결들이 매우 비슷한거 같습니다. (Portoflio, LLM도 맛보시는듯?, household, 개인금융...)그 중에서 QF에 억셉된, deep learning asset pricing류의 논문을 하나 발견해서 골라봤습니다. 2021년에 투고한 논문이라 생각보다 내용이 딥러닝적으로 엄청난게 있는 것 같지는 않습니다. risk premia를 예측하기 위해 ML을 사용하고, LIME으로 explainability를 챙기고자 했던 연구입니다.  읽기에도 어렵지 않고, 다양한 이야기들을 해볼 수 있지 않을까? 해서 골라봤습니다. 여기 연구실 연구들도 가끔씩 들어가서 재밌는 연구들 있으면 읽어보면 재밌을 것 같아서 한번씩 살펴보시는 걸 추천드립니다.",
    "url": "https://www.tandfonline.com/doi/epdf/10.1080/14697688.2023.2203844?needAccess=true"
  },
  {
    "date": "2024년 08월 14일",
    "title": "Generative Learning for Financial Time Series with Irregular and Scale-Invariant Patterns",
    "presenter": "Juchan Kim",
    "reason": "금융 시계열은 일반적인 시계열과는 약간 다른 특징을 지녔기에, 시계열 데이터에서 사용할 수 있는 데이터 증강 기법을 그대로 사용하기 어렵습니다. 이는, 금융 시계열의 벤치마크 데이터셋에도 크게 영향을 줘 JP morgan 같은 세계적인 기업에서도 금융 시계열의 데이터 증강 및 합성데이터 생성은 여전히 challenging problem으로 남아있습니다. 본 연구에서 다루고자 하는 문제도 금융 시계열에서의 데이터 합성 및 증강 기법을 다루며, 이를 위해 금융 시계열과 일반적인 시계열 데이터의 차이점을 (i) irregularity (ii) scale-invariance로 크게 꼽습니다. 언급한 이러한 문제를 해결하기 위해 생성 모델인 diffusion probabilistic model과 pattern clustering을 위한 k-mean clustering을 적절히 사용해 pattern recognition - generation - evolution의 3가지 단계를 결합한 FTSDiffusion model을 제시합니다. 또한, 실험을 통해 해당 방법론이 좋은 퀄리티의 synthetic data를 만들어낼 수 있을 뿐 아니라, 합성 데이터를 통해 stock market prediction task를 진행했을 때도 오차를 상당 범위 줄일 수 있었다고 합니다.",
    "url": "https://openreview.net/forum?id=CdjnzWsQax"
  },
  {
    "date": "2024년 07월 25일",
    "title": "M3PL: Identifying and Exploiting View Bias of Prompt Learning",
    "presenter": "Inwoo Tae",
    "reason": "해당 논문은 현재 TMLR에서 심사 중인 논문으로, openreview에 올라온 논문입니다. 기존의 CLIP 같은 경우, 이미지와 텍스트를 동시에 학습하여 다양한 비전과 언어 작업에서 성능이 좋은 multi modal model로,  대규모 이미지-텍스트 쌍을 학습 데이터로 사용하며, 대조 학습(Contrastive Learning) 방법을 통해 이미지와 텍스트의 임베딩을 동일한 의미 공간으로 매핑하여 제로샷을 통해 학습이 진행됩니다.\n하지만 CLIP의 문제점은 학습된 프롬프트가 기능의 일부분만 집중하는 뷰 바이어스(View Bias) 현상으로 인해 모델의 OOD(Out-Of-Distribution) 강건성이 저해될 수 있다는 점이 있습니다. 이러한 문제점을 해결하기 위해 본 논문은 M3PL(Multi-modal Matching Multi-Prompt Learning) 프레임워크를 제안하였습니다. M3PL은 여러 프롬프트 쌍을 사용하고 cross-modal contrastive regularizer를 도입하여 다양한 기능을 포착하고 view bias를 완화하여 모델의 일반화 성능을 개선하였습니다.\n저도 간단하게 읽어봤는데, 재미있을 것 같아서 한 번 읽어보고 다양한 관점에서 논의하면 좋겠습니다.",
    "url": "https://openreview.net/pdf?id=2rnTIBm19V"
  },
  {
    "date": "2024년 07월 25일",
    "title": "Pathformer: Multi-Scale Transformers with Adaptive Pathways for Time Series Forecasting",
    "presenter": "Kangmin Kim",
    "reason": "이번에 제가 소개할 논문은 2024년 ICLR에 accpeted된 https://arxiv.org/abs/2402.05956입니다. Transformer구조를 활용한 시계열 예측모델은 많이있는데요, Pathformer는 Dual Attention을 통해 short-term series간의 correlation, long-term series간의 correlation을 파악할 수있고, adaptive pathways 구조를 필요한 patch만 선택해 시계열 예측 성능을 향상시켰다고합니다.patch size를 여러개 사용하는 아이디어는 이미 있기는 하지만 transformer구조를 활용하고, 중요한 patch를 선정한다는 아이디어가 흥미로워 선정해보았습니다.\n",
    "url": "https://arxiv.org/abs/2402.05956"
  },
  {
    "date": "2024년 07월 18일",
    "title": "The effects of errors in means, variances, and correlations on the mean-variance framework",
    "presenter": "Junhyeong Lee",
    "reason": "저희가 MVO를 이용하기 위해서는 mu와 sigma를 잘 설정해줘야합니다. 그러나 이를 정확하게 아는 것은 거의 불가능할 뿐 아니라, mvo는 추정값들의 오류들에 대해서 매우 민감하게 반응합니다. 이 논문은 이러한 현상들에 대해서 잘 분석한 논문입니다. UDRP등을 이용해 가능한 투자 시나리오에서 발생할 수 있는 sharpe ratio의 distribution을 분석하는 식으로 결과를 보여주는 것 같습니다.저희 DFL 논문에 인용할 다양한 논문 중 하나이고, 인턴 분들도 재밌게 읽을 수 있을 것 같아서 선정해보았습니다.",
    "url": "https://www.tandfonline.com/doi/full/10.1080/14697688.2022.2083009"
  },
  {
    "date": "2024년 07월 11일",
    "title": "Model-free and Model-based Learning as Joint Drivers of Investor Behavior",
    "presenter": "Yongjae Lee",
    "reason": "행동경제학 분야에서 좋은 연구 많이 하고 계시는 Yale의 Nicholas Barberis 교수님의 최근 working paper입니다. 심리학자, 신경과학자들이 사람의 의사결정이 model-free와 model-based system 두 가지에 의해서 이루어진다고 이야기 한다고 합니다. 좀 거칠게 이야기하자면은 model-free system은 무의식적인 파트를 이야기하는 것 같고, model-based system은 이성적인 파트를 이야기하는 듯 합니다. 이 연구에서는 이를 간단한 금융 투자 세팅에서 시뮬레이션해보고, 투자자의 행동에 대한 여러 과거 연구의 finding과 연결지으려는 시도를 합니다. 개인투자자의 투자를 더 깊게 이해하는데 도움이 될 것 같아서 골라보았습니다.",
    "url": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4331775"
  },
  {
    "date": "2024년 07월 04일",
    "title": "Distributionally robust end-to-end portfolio construction",
    "presenter": "Inwoo Tae",
    "reason": "해당 논문은 Roy Kwon 교수님 연구실에서 PhD를 마친 Giorgio Costa의 논문으로, 23년 QF에 accept된 paper입니다. 역시 DFL 논문이며, 자산 수익률을 예측하되, 포트폴리오의 수익을 최대하면서 위험을 최소화하는 것을 objective로 decision을 결정합니다. 따라서 기존 연구에서 대부분 사용된 predict then optimize(PO) 방법과 DFL이 적용된 distributionally robust(DR) 방법의 실험을 비교하여, 리스크 허용 정도를 조절하는 γ와, δ로  ambiguity set의 크기를 조절해 distributional robustness의 정도에 따른 결과를 비교합니다. 실험은 미국 주식 시장의 과거 데이터로 진행하였으며, 그 결과 DR 방법의 PO보다 높은 수익과 낮은 변동성을 제공하는 것을 보여줌으로써, 모델의 유용성을 보여줍니다. 해당 논문 읽으면서 DFL 쪽에 아이디어 있으면 편하게 논의하면 좋을 것 같습니다!",
    "url": "https://www.tandfonline.com/doi/full/10.1080/14697688.2023.2236148"
  },
  {
    "date": "2024년 07월 04일",
    "title": "Why warmup the learning rate? Underlying mechanisms and improvements",
    "presenter": "Juchan Kim",
    "reason": "딥러닝 모델을 훈련하는 과정에서 optimizer마다 갖춘 learning rate 를 정해 loss function을 최적화해나가는데, 이 때 fix되어있는 learning rate를 그대로 사용하면 학습이 불안정한 경우가 많아 실질적으로는 learning rate를 schedule하는 과정을 거칩니다. 여기서 자주 사용되는 방법은 learning rate warmup 이라고 해서 학습 초기에 둘 learning rate부터 target하는 learning rate까지 점차 증가시키는 방법이 있습니다. 본 논문에서는 learning rate warmup을 사용해야 하는 이유를 loss landscape의 sharpness를 이용해 설명합니다. 특히, warmup period를 얼마나 길게 잡느냐에 따라서의 sharpness와 test loss를 비교하는 등의 실험을 통해 어떻게 warmup scheduling을 할지에 대한 가이드라인과 initial learning rate scheduling에 대한 guide도 약간은 잡아주는 것 같습니다.이론적인 내용은 크게 없고, 실험적으로 SGD / adam optimizer에서 warmup period / maximum learning rate 등을 바꿔가며 앞서 말한 (1) sharpness, (2) test error 같은 기준들을 비교해보는 것이 내용이니 보시고 다양하게 의견 교환 가능할 것 같아 선정하게 되었습니다.",
    "url": "https://arxiv.org/abs/2406.09405"
  },
  {
    "date": "2024년 06월 28일",
    "title": "Insensitive Investors",
    "presenter": "Kangmin Kim",
    "reason": "첫 저널클럽에 소개할 논문은 2022년에 ssrn에 올라오고, Journal of Finance에 올해 5월에 올라온 Insensitive Investors입니다.\n논문에서는 투자자들의 정확한 asset pricing을 방해하는 요소가 cognitive noise라고 합니다. cognitive noise로 인해 그들의 기대에 비해 평가가 너무 둔감하게 나타납니다.\n실험 결과는, 주관적 기대가 1 단위 증가할 때, 투자자의 지불 의사는 평균적으로 0.61 단위 증가하는데 그쳤습니다. 이론적으로 기대 수익률이 높아지면 그만큼 지불 의사도 동일하게 증가해야 하지만, 실제로는 그렇지 않다는 것으로 cognitive noise에 대한 검증을 하였습니다.\n개인 투자자들의 행동과 관련한 논문이라 재미있게 읽으실 수 있을 것같습니다.",
    "url": "https://onlinelibrary.wiley.com/doi/abs/10.1111/jofi.13362"
  },
  {
    "date": "2024년 06월 28일",
    "title": "Enhanced Portfolio Optimization",
    "presenter": "Suhwan Park",
    "reason": "제가 이번에 고른 논문은 AQR에서 나왔으며 Financial Analysts Journal에 실린 “Enhanced Portfolio Optimization” 이라는 논문입니다.교수님의 금융인공지능 강의를 수강하며 여러 MPT 관련 이론들을 가볍게 접했는데요, 이번 기회에 자세히 공부하고자 포트폴리오 최적화 관련 논문을 선정하였습니다. 어렵지 않은 논문이라 상대적으로 쉽게 읽으실 수 있을 것 같습니다.모두 아시다시피 포트폴리오 최적화 중에 가장 기본이 되는 MVO는 공분산을 estimate 하는 과정에서 noise가 들어가 out of sample 퍼포먼스가 좋지 않다는 문제점이 있습니다. 논문에서는 이러한 노이즈가 어떤 이유와 어디서 발생하는지 PCA를 통하여 살펴본 뒤 그것을 보완하는 해결방안인 EPO를 (Enhanced portfolio optimization) 제시합니다.PCA를 통해 발견된 주요 결과는 다음과 같습니다:MVO에서 가장 중요하지 않은 PCs의 out-of-sample volatility, return, sharpe ratio가 실제 값과 크게 차이나는 경우가 많다는 점입니다. 특히, 이러한 PCs의 예측된 SR은 실제 값보다 over-estimated 된다고 합니다. 저자들은 이러한 문제를 해결하기 위한 방법으로 SR의 분모에 해당하는 estimated volatility를 증가시키는 것을 제안합니다. volatility를 증가하는 것은 correlation을 0에 가깝게 shrinkage 하는 것과 같은 효과이며 이를 논문에서는 simple EPO라는 방법으로 소개합니다.",
    "url": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3530390"
  },
  {
    "date": "2024년 05월 09일",
    "title": "KAN: Kolmogorov-Arnold Networks",
    "presenter": "Yongjae Lee",
    "reason": "MIT, CalTech 등의 저자들이 며칠 전에 아카이브에 공개한 논문인데요, 요새 하도 난리이길래 궁금해서 한번 같이 이야기 나눠보고싶어서 골라봤습니다. node에 고정된 activation function을 두는 MLP 대신에 edge에 learnable activation function을 두고 weight parameter도 linear가 아니라 spline으로 parameterized 된 univariate function으로 대체되어있다고 합니다. 이론적으로나 실험적으로나 MLP보다 여러 면에서 성능이 좋다고 이야기를 하고 있고, 설명가능성도 더 좋다고 하네요. 지난 몇 년간 잠깐 떠들썩 하다 흐지부지 사라진 네트워크 구조가 한두개가 아닌데요 이번에는 실제로 MLP가 대체가 될런지 어떨지 궁금합니다.",
    "url": "https://arxiv.org/abs/2404.19756"
  },
  {
    "date": "2024년 04월 11일",
    "title": "An Investigation into Neural Net Optimization via Hessian Eigenvalue Density",
    "presenter": "Junhyeong Lee",
    "reason": "이번 논문은 neural net 최적화에 관한 논문입니다. 저자들은 최적화 과정 전반에 걸쳐서 Hessian spectrum이 어떻게 변화하는지를 관찰하는 방법을 제안합니다. 기존 수치해석 쪽에서 존재했던 알고리즘을 바탕으로 딥러닝 최적화에 적용한 것 같습니다. 논문에서는 저자들이 제안하는 방법론을 바탕으로 기존에 널리 알려져 있던 다양한 학습 과정에 관련된 가설들에 대한 이야기를 합니다.UofT에서 MDP 수업을 듣다가 강화학습 관련해서 https://proceedings.neurips.cc/paper_files/paper/2001/file/4b86abe48d358ecf194c56c69108433e-Paper.pdf(강화학습에서의 PPO알고리즘까지 연결되는 아주 중요한 논문!) 라는 논문을 발표하게 되었는데, 이때 인공지능에서의 최적화에 나름 흥미가 생겨서 이번에도 관련된 논문으로 가져와봤습니다. 이전 저널클럽에서도 다양한 분들이 hessian이나 최적화 관련된 논문들을 발표해주셨기 때문에, 이번에도 재밌게 볼 수 있을 것 같습니다!",
    "url": "https://arxiv.org/abs/1901.10159"
  },
  {
    "date": "2024년 03월 28일",
    "title": "Do Emotions Influence Investor Behavior?",
    "presenter": "Yejin Kim",
    "reason": "이 논문은 Journal of Behavioral FInance에 2023년 publish된 논문입니다. 제목이 흥미로워보여서 고르게 되었는데요, 감정이 의사결정에 어떤 영향을 미치는지에 대해 연구한 논문입니다. 이 논문에서는 뉴스와 소셜 미티어에서 추출한 감정이 투자결정과 자산가격 결정에 미치는 영향을 평가했습니다. 결과적으로는 감정이 투자자의 의사결정에 영향을 미친다고 하고요, 특히 신뢰나 낙관주의와 같은 긍정적인 감정이 투자자의 반응을 형성하는데 더 영향을 미친다고 합니다. 그리고 뉴스 미디어가 sns 보다 주식 가치 평가에 더 큰 영향을 미쳤다고 합니다. 간단한 논문인 만큼 데이터에서 어떤식으로 인사이트를 찾았는지 중점적으로 보면 좋을 듯 합니다!!",
    "url": "https://www.tandfonline.com/doi/full/10.1080/15427560.2023.2282966"
  },
  {
    "date": "2024년 03월 21일",
    "title": "Stealing Part of a Production Language Model",
    "presenter": "Inwoo Tae",
    "reason": "이 논문은 최근 Google DeepMind에서 발표한 논문으로, ChatGPT와 같이 생산 언어 모델을 제공하는 API의 layer를 탈취할 수 있다는 이야기를 합니다. 트랜스포머 모델의 경우 내부에는 수많은 layer들이 존재하지만, 결국 최종적으로는 이를 토큰으로 매핑하게 되어야 하는데, 이 때 기존의 layer에서 토큰으로 변환해야 되는 상대적으로 굉장히 작은 h차원에 임베딩 정보가 모이게 됩니다. 즉 token logit 자체가 h차원의 부분 공간에 존재하게 되어 이를 아이디어로 해당 레이어의 w값을 얻을 수 있다는 것이 이 논문의 핵심입니다. 실제로 저자들은 이를 OpenAi의 GPT-3.5-turbo-instruct, GPT-3.5-turbo-chat에 공격이 효과적임을 입증하였고, 3월 3일 OpenAI가 취약점을 완화하여 해당 논문을 발표했다고 합니다. 물론 아직 제한점이 훨씬 많지만, 이를 적은 비용으로도 특수한 경우에는 가능하다는 점이 인상적인 논문입니다. 읽어보고 다양한 토의가 나오면 좋겠습니다!",
    "url": "https://arxiv.org/pdf/2403.06634.pdf"
  },
  {
    "date": "2024년 03월 14일",
    "title": "A Topology-aware Analysis of Graph Collaborative Filtering",
    "presenter": "Youngbin Lee",
    "reason": "제가 주로 했던 연구가 추천시스템 중에서도 graph collaborative filtering 인데요, 유저 및 아이템의 임베딩을 잘 학습한다는 관점에서 기존 알고리즘을 공부하고 새 알고리즘을 고민해 봤지만 그래프의 위상구조를 다양하게 살펴보고 분석해 본 적은 없는 것 같습니다. 이 논문에서는 어떤 topology 특성이 추천 성능에 영향을 미치는지 그 선형 관계를 분석했는데요 이러한 내용을 알아 두면 GNN이 어떨 때 왜 잘 작동하는지 추천시스템 측면에서 이해할 수 있을 것 같습니다 🔥",
    "url": "https://arxiv.org/abs/2308.10778"
  },
  {
    "date": "2024년 02월 14일",
    "title": "On the joint interaction of models, data and features",
    "presenter": "Juchan Kim",
    "reason": "딥러닝에 대한 근본적인 이해를 도울 수 있는 내용일 것 같아 선정하게 되었습니다. 딥러닝에서 모델이 어떻게 feature를 학습하는지에 관한 내용은 실험적으로 뜯어보려는 연구 정도가 있었는데요. 다만 여기서의 문제점은 개별적인 모델 단위의 분석만 있을 뿐 딥러닝 전반에서의 data의 feature 관련한 정의라던지 이런 것들이 없다는 점입니다. 본 논문에서는 feature라는 것을 last-layer activation 에서의 principal component 라고 정의하고, 여기서 얻어낸 값을 토대로 interaction tensor 라는 모델, 데이터 그리고 앞서 정의한 feature 를 하나로 아우를 수 있는 텐서를 정의합니다. 이러한 interaction tensor를 이용했을 때, 딥러닝에서 보여지는 다양한 현상들을 여러 가정이나 이런 것 없이 설명할 수 있었다고 합니다.",
    "url": "https://openreview.net/forum?id=ze7DOLi394"
  },
  {
    "date": "2024년 02월 08일",
    "title": "The Gerber statistic: a robust co-movement measure for portfolio optimization",
    "presenter": "Seyoung Kim",
    "reason": "이 논문은 포트폴리오 이론에서 오랫동안 사용된 MVO(Mean-Variance Optimization) 모델의 한계점을 개선하기 위한 새로운 접근법을 제시하고 있습니다. 모두가 잘 알듯이 MVO 모델의 한계점은 평균(mean), 분산(variance), 상관관계(corr) 등 여러 파라미터들의 추정 오류가 너무 민감하다는 것입니다. 이를 해결하기 위해 Gerber와 Markowitz 교수님이 공저자로 참여하여 Gerber statistic을 제안하며, 이를 통해 robust한 covariacne  matrix 추정 방법을 소개하고 실험한 논문입니다.\nMVO 모델에서는 과거 특정 기간을 기반으로 자산 간의 평균과 공분산 행렬을 추정하게 됩니다. 이 과정에서 shrinkage estimator를 사용하여 공분산 행렬 추정 오류를 줄이는 방법이 널 알려져 있습니다. 그러나 이 방법은 샘플 공분산을 사용하므로 극단적인 값(노이즈)이 포함될 수 있다는 단점이 있습니다.\nGerber statistic은 두 자산의 수익률이 동시에 어떤 threshold를 기준으로 같은 방향, 다른 방향, 또는 그 사이에 있는지를 쌍으로 구분하여 자산 간의 동조성을 나타냅니다. 이때 threshold는 자산의 표준편차에 가중치 c를 곱하여 결정되고, 이로 생성된 Gerber matrix에 각 자산의 표준편차의 대각행렬을 양쪽에 곱하여 Gerber covariance matrix을 계산합니다. 이렇게 공분산을 추정하면 극단적인 움직임에 대한 왜곡 없이 자산간의 관계를 추정할 수 있으며, 11개의 다양한 자산군으로 이루어진 포트폴리오 백테스팅에서 기존의 MVO의 historical covariance, shrinkage method보다 높은 투자 성능을 기록함으로써 기존 방법보다 robust함을 보였다고 합니다.\n현재 제가 GAN으로 하고 있는 robust portfolio optimization 확장 연구에 이 방법도 적용해서 manual하게 정해줘야 하는 threshold parameter를 시장 상황에 반영하여 효율적으로 조절하는 실험을 계획중입니다. RPO에 대한 다양한 접근과 최근 제안된 이러한 방법에 대해 다같이 알아두면 좋을 것 같아 선정했습니다!",
    "url": "https://www.pm-research.com/content/iijpormgmt/48/3/87"
  },
  {
    "date": "2024년 02월 08일",
    "title": "Mean-variance portfolio optimization based on ordinal information",
    "presenter": "Yongjae Lee",
    "reason": "얼마 전에 Annals of Operations Research에 논문 review 요청이 와서 하다가 거기에 cite 되어있어서 알게 된 논문인데 나름 흥미롭기도 했고, 현재 하려는 연구들과 관련 있어보여서 소개하면 좋겠다 싶었습니다.\nBlack-Litterman model은 Black과 Litterman이 Goldman Sachs에서 일하던 시절에 MVO에 자산 수익률에 대한 특정한 view를 넣기 위해 Bayesian 방법을 활용하여 만든 모델이고 지금까지도 많이 활용되고 있습니다. 하지만 이게 사용이 약간 어려울 수 있는 부분이 바로 특정 자산의 기대수익률 또는 특정 자산이 다른 자산 보다 몇 % 수익률이 높을지를 숫자로 제시해야한다는 것입니다. 그래서 큰 금융기관에서야 원래 하는 일이니 가능하겠지만 그 외에는 사용하기가 조금 어려운 모델입니다.\n이 연구에서는 자산 A가 자산 B보다 수익률이 클 것 같다’ 라는 식의 순서만 제시할 수 있도록 Black-Litterman의 수식을 살짝 바꾸고 이를 실제 계산할 수 있도록 고민을 하였습니다. Black-Litterman을 잘 알고 있다면은 그닥 어려운 부분은 없고요, 만약에 잘 몰랐다면은 이 기회에 한번 잘 살펴보시면 여러모로 도움이 될거라 생각합니다.\n저희 연구에 도움이 되겠다 생각한 이유는 첫 번째로는 추천시스템이 보통 item들의 ranking을 매기는 것에 집중하고 있습니다. 즉, 개인의 preference라는 것이 결국에는 item들의 ranking 형태로 나오게 될 가능성이 높으니, 이 연구에서 제시하는 모델이 이러한 형태의 정보를 MVO에 반영할 수 있는 모델이지 않을까 싶었습니다. 두 번째로는 MVO + SPO 관련해서도 Black-Litterman에 대해서 잘 알아두고 이의 variant도  공부하다보면은 좋은 아이디어가 떠오를 수도 있지 않을까 싶었습니다.",
    "url": "https://doi.org/10.1016/j.jbankfin.2020.105989"
  },
  {
    "date": "2024년 02월 02일",
    "title": "Add and Thin: Diffusion for Temporal Point Processes",
    "presenter": "Juchan Kim",
    "reason": "NIPS'23 에 accept 된 논문이고, TPP를 잘 모델링하기 위해서 Diffusion probabilistic model 과 Homogeneous Poisson Process(HPP) 를 잘 결합해본 논문입니다. 기존에 써왔던 디퓨전의 구조를 그대로 활용하기에는 시계열 모델링과 이미지 쪽의 차이가 워낙 커서, 저자들이 따로 forward, backward process 를 정의하고, variational inference 를 위한 ELBO 에 대한 이론적 분석, 그리고 샘플링에 대한 과정까지 다 보여주었습니다. 이론적으로도 볼 가치도 충분히 있을 뿐더러, 실험 결과도 상당히 좋아보여 저널클럽 발표 주제로 정하게 되었습니다.",
    "url": "https://arxiv.org/abs/2311.01139"
  },
  {
    "date": "2024년 02월 02일",
    "title": "Frequency-domain MLPs are More Effective Learners in Time Series Forecasting",
    "presenter": "Yoontae Hwang",
    "reason": "제 차례인지 몰라서 좀 늦게 올렸습니다.. 그 시계열에 관련된 연구인데 DLinear가 왜잘되는지를 이 논문을 통해서 얼핏이나마 알 수 있을것 같아서 선정했습니다. 중간에 읽다가 좀 더 세부내용 추가하겠습니다!",
    "url": "https://openreview.net/forum?id=iif9mGCTfy"
  },
  {
    "date": "2024년 01월 25일",
    "title": "A Multimodal Embedding-Based Approach to Industry\nClassification in Financial Markets",
    "presenter": "Inwoo Tae",
    "reason": "늦게 올려서 죄송합니다 ㅠㅠ. 앞으로 어떤 연구를 해야 할지 고민하던 중에, 윤태형의 SimStock처럼 주식 간의 representation을 추출하는 연구를 해보고 싶어서 관련 논문을 찾아보았는데, 주가 데이터와 관련 news 데이터를 엮어서 representation를 추출하길래 한 번 읽어보았습니다.작년에 세영님이 journal club에서 발표해주신 https://www.sciencedirect.com/science/article/pii/S003132032100399X 와 유사하게 주가 정보와 text 데이터들을 multimodal로 학습시킨 모델인데, 해당 논문의 목표는 stock의 industry classification을 목적으로 제작이 되었습니다.내용 자체가 어렵지 않아서 쉽게 읽으실 수 있습니다. 보통 기존의 knowledge graph는 텍스트 기반으로 제작이 되는데, historical return을 embedding해서 graph로 표현한 figure가 앞으로 제 연구를 어떻게 시작해 나갈지 고민하게 되는 계기를 만들어줘서 해당 논문으로 최종 결정하게 되었습니다. 읽으면서 혹시 비슷한 연구나 추천해주시고 싶은 paper있으시면 댓글로 알려주시면 감사하겠습니다!",
    "url": "https://arxiv.org/pdf/2211.06378.pdf"
  },
  {
    "date": "2024년 01월 24일",
    "title": "A cost-sensitive ensemble deep forest approach for extremely imbalanced credit fraud detection",
    "presenter": "Yejin Kim",
    "reason": "이 논문의 QF에 accept된 논문이구요, 조만간 금융 데이터로 graph anomaly detection 논문을 쓰게 될 수도 있어 교수님께서 보내주신 논문입니다! 이 논문도 영빈님이 저번주에 소개한 논문과 같은 문제인 “class imbalance” 문제를 다루는 논문인데요, 이 논문에서는 문제를 해결하기 위해서 deep forest framework에서 cost-sensitive ensemble model을 개발하였습니다. 모델은 우선 fraud class에 더 높은 cost를 주는 cost-sensitive strategy를 사용하구요, 앙상블 기법에 diversity를 주고 performance를 높여주기 위해서 cost-sensitive base classifiers를 cascade structure에 넣어주었다고 합니다. 또한 모델은 Type 2 error를 convergence index로 사용해서 cascade structure의 depth를 조절한다고 합니다. European credit dataset과 private electronic transaction dataset을 통해서 제안한 모델을 실험해본 결과 다른 benchmark들 보다 performance의 향상이 있었다고 합니다! 저번주 논문과 비슷한 만큼 각 접근 방식을 비교해보고 의논해볼 수 있는 시간이 되었으면 합니다…!!",
    "url": "https://www.tandfonline.com/doi/full/10.1080/14697688.2023.2230264"
  },
  {
    "date": "2024년 01월 18일",
    "title": "GraphSMOTE: Imbalanced Node Classification on Graphs with Graph Neural Networks",
    "presenter": "Youngbin Lee",
    "reason": "제가 그래프 기반 추천시스템을 해 오다 보니 GNN이랑 node classification도 자주 마주치게 되었는데요, 조만간 금융 데이터로 graph anomaly detection 논문을 쓰게 될 수도 있어서 class imbalance 문제를 다룬 논문을 골랐습니다. 이 논문은 minority node를 over-sampling하는 방식으로 문제를 해결합니다. 널리 쓰이는 oversampling 기법인 SMOTE를 사용하는데, 노드끼리의 관계를 고려한다던지 이웃 노드끼리 i.i.d 하지 않다던지 하는 그래프의 특성에 맞게 이를 확장해서 사용했습니다.",
    "url": "https://arxiv.org/abs/2103.08826"
  },
  {
    "date": "2024년 01월 18일",
    "title": "Differentiation of Blackbox Combinatorial Solvers",
    "presenter": "Junhyeong Lee",
    "reason": "새해 첫 저널클럽이네요 ㅎㅎ 올해도 잘 부탁드립니다 여러분!이번 논문은 ICLR 2020에 publish된 논문입니다.보통 최적화의 경우 실행 시간과 성능에 대해서 이론적으로 보장된 방법론들이 존재합니다. 그러나 복잡성이 높은 데이터에서의 활용이나 practical한 접근을 위해 딥러닝과 이런 최적화 방법론을 같이 다룰 수 밖에 없는 경우들이 있습니다. 이렇게 섞게 될 경우에, 미분 가능성에 대한 내용이 아주 중요한 문제가 됩니다. 그렇기에 많은 연구들에서는 surrogate loss function을 제안하거나, 다양한 조건들을 완화하여 이런 문제를 다룹니다. 이 논문에서는 linearization을 통해 gradient를 대체해서 구하게 되고, 우리에게 나름 익숙한 piecewise한 접근을 통해 연속성에 대한 증명을 보입니다.이런류의 연구들을 Neural Combinatorial Optimization이라고 부르는 것 같더라구요. 검색해보면 자료가 많이 나오니 관심 있으신 분들은 찾아보셔도 좋을 것 같습니다.추가적으로, 발표 하고 싶었던 논문 중에 https://arxiv.org/pdf/2305.17570.pdf(NIPS 2023 Oral) 도 있었는데, 한 번 읽어보셔도 재밌을 거 같아서 남깁니다!",
    "url": "https://arxiv.org/pdf/1912.02175.pdf"
  },
  {
    "date": "2023년 12월 07일",
    "title": "Household financial health: a machine learning approach for data-driven diagnosis and prescription",
    "presenter": "Yoontae Hwang",
    "reason": "12월 7일 저널클럽에서는 제가 작성했던 household financial health에 대해서 살펴볼려고 합니다. 여기에는 몇가지 모티베이션이 있지만 제가 생각했을때 중요한 모티베이션은 다음과 같습니다.\n• 사실 기존의 선행연구들에서는 소위 \"전문가\"들의 의견으로 가계가 건전한지 아닌지를 알려주었습니다. 또, 이러한 지표들은 개인에게 맞춤화되었다기 보다는 \"정해진\"값에 의존하였기 때문에, 개개인의 상태에 적합한 재무적 조언을 해주기 어렵습니다. 이로 인해, 재무목표에 맞게 자산을 배분하고 투자를 실행하는 이러한 일련의 과정이 매우 고비용으로 측정되어 일반인들은 접근이 어렵습니다(은행에서 WM 부문)\n• 이러한 가계의 재무 조언을 위한 WM은 여러 세부분야로 나뉠 수 있습니다.  예를들어,\n• 투자 설계 : 지금 연구실에서 수행하는 추천시스템이 이런 핏이라고 생각합니다.\n• 은퇴 및 재무 설계 : 모딜리아니의 생애주기가설을 고려하면, \"경제활동기\"에서 재무적 혹은 비재무적인 준비를 통해 행복한 은퇴를 설계해야만 행복한 삶을 살 수 있다고 합니다. 이 논문에서 주로 다루는 부분은 이 파트입니다.\n• 위험 설계 : 개개인의 위험요소를 분석해서, 적절한 보험상품을 선정해주고, 바람직한 보험설계를 위해서 발생하는 비용과 얻어지는 혜택사이의 균형을 이루도록 하여 위험(특히 의료)을 최소화 하고자 하는 과정입니다.(저희 연구실에서 의료비 연구와 관련이 있다고 생각합니다)\n• 세금 설계 : 모든 사람들은 요람에서 무덤까지 평생 동안 세금을 떠나서 살 수 없기 때문에, 합법적으로 세금을 절세할 수 있는 전략들을 고민하는 분야입니다. 주식의 세금 뿐만 아니라, 좀 더 포괄적으로 상속세, 증여 등 다양한 것들이 포함됩니다.제가 생각하기에 보통 사람들에게 있어서, 중요한것은 위에서 설명한 여러 세부분야들을 통합함으로써 가계의 건전성과 은퇴후 삶을 설계할 수 있다고 생각합니다. 이 논문에서는 가계의 \"재무상태\"에 대해서 어떻게 \"진단\"하고 \"처방\"해야할지를 탐구합니다. 앞으로 가계금융데이터는 매년 업데이트가 되고 있고, 특히 주식투자에 대한 항목들도 최근 추가되고 있어서, 더욱 발전될 여지가 있다고 생각합니다.",
    "url": "https://www.tandfonline.com/doi/epdf/10.1080/14697688.2023.2254335?needAccess=true"
  },
  {
    "date": "2023년 11월 16일",
    "title": "Taming Pretrained Transformers\nfor Extreme Multi-label Text Classification",
    "presenter": "Seonmi Kim",
    "reason": "지금 진행하고 있는 허그랩 프로젝트가 아무래도 텍스트에 알맞는 키워드를 매칭해주는 것이다보니 요즘은 nlp 관련 논문들을 주로 읽고 있는데 마침 저희가 하고있는 프로젝트와 아주 유사한 태스크를 연구한 논문을 드디어 찾아서 다같이 읽고 이야기해보면 좋을 것 같아 선정해보았습니다. 그리고 nlp 논문이긴 하지만 생각보다 nlp specific knowledge를 다루지는 않는 것 같아 다들 편하게 읽으실 수 있을 것 같습니다. 해당 논문은 아마존과 cmu가 공동진행한 연구인데요 아마존은 아무래도 물건의 개수도 엄청 많고 해당 물건들을 분류하는 카테고리들도 많다보니 빠르고 효율적으로 트랜스포머 기반의 모델을 사용해서 각 물건들을 알맞는 카테고리에 빠르게 매칭할 수 있는 방법을 제시합니다. 모델을 간략히 요약하자면 (1) 제일 먼저 수많은 레이블들을 클러스터링해줘서 레이블 서치할 범위를 줄여주고. (2) 트랜스포머 모델이 각 Instance(e.g. 아이템)들을 알맞는 클러스터들에 매핑할 수 있도록 파인튜닝을 시키고 (3) 2가지 네거티브 샘플링을 통해 각 instance에 알맞는 레이블들을 추천해주는 방식을 채택하고 있습니다. 허그랩 프로젝트에 참여하면서 모델링 방법 뿐만 아니라 문제 접근 방식, EDA 등 이것저것 아이디어들이 더 필요했는데 이 논문을 보면서 연구 방향에 대한 확신과 아이디어들을 얻을 수 있었던 것 같습니다.",
    "url": "https://dl.acm.org/doi/10.1145/3394486.3403368"
  },
  {
    "date": "2023년 11월 09일",
    "title": "Integrating prediction in mean-variance portfolio optimization",
    "presenter": "Yongjae Lee",
    "reason": "이번 논문은 U Toronto의 Roy Kown 교수님의 최근 QF 논문을 골라왔습니다. 예전에 준형 학생이 실제 의사결정 최적화 문제의 objective를 prediction에도 반영하기 위한 smart predict-then-optimize (SPO) 논문 (Elmachtoub & Grigas, 2022, MS)을 발표한 적이 있었죠. 거기에도 portfolio optimization 예시가 있긴 했었는데 실제 실험 디테일을 살펴보니 주식 관련 데이터를 적당한 random variable로 생성해서 테스트 했던 것이더라고요. 그래서 딱히 의미있는 실험결과였다고 보기는 좀 어려울 것 같습니다. 여튼 이번 논문 역시 SPO 논문같이 prediction과 optimization을 integrate 하겠다는 것은 동일 합니다. 다만 이 논문은 일단 mean-variance portfolio optimization만을 다루고 있고, prediction model을 linear regression 모델로 한정지었습니다. 그렇게 한 이유는 (적어도 최근 MS 논문에 제시된 버전에서는) SPO가 linear objective function을 가지는 경우에 대해서만 가능한데, MVO는 QP이니 수식 derivation을 위해서 그런 것으로 보입니다. 참고로 SPO에서는 variance를 objetive가 아니라 constraint에 두는 formulation으로 실험을 한 듯 했습니다. (즉, linear objective, quadratic constraint) 그리고 이 논문은 commodity futures market 데이터를 사용해서 일단 실제 데이터를 사용하기는 했습니다.",
    "url": "https://www.tandfonline.com/doi/full/10.1080/14697688.2022.2162432"
  },
  {
    "date": "2023년 11월 02일",
    "title": "Honey, I shrunk the sample covariance matrix",
    "presenter": "Juchan Kim",
    "reason": "Mean-variance optimization(by Markowitz) 에서는 risk minimization 을 위해 covariance matrix 가 필요하고, optimization 하는 시점에서는 covariance matrix 를 직접 구하기는 어렵기 때문에 대부분 estimator 를 이용하곤 합니다. 달리 말해, 이런 공분산을 잘 추정하는 estimator 를 만드는 것도 하나의 중요한 task 로 생각할 수 있다는 것입니다. 본 논문에서도 말하는 내용 역시 간단합니다. 공분산 행렬을 잘 추정하는 estimator 를 만들고, 이를 통해 portfolio optimization 을 하면 성능이 잘 나온다는 것입니다. 좀 더 자세하게 말씀드리면, 여기서의 estimator 는 unstructured estimator S (e.g. 과거 공분산 행렬) 와 우리가 구해내는 structured estimator F 의 convex combination 형태로 표현됩니다. 이 논문에서 주로 밝히는 것은 여기서 F 와 convex combination coefficient 를 어떻게 둬야 optimal 한 estimator 가 될 수 있을까에 대한 내용입니다.",
    "url": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=433840"
  },
  {
    "date": "2023년 10월 05일",
    "title": "Fairness in Matching under Uncertainty",
    "presenter": "Seongjin",
    "reason": "이번에 발표할 논문은 ICML 2023에서 Poster로 발표된 논문입니다. 최근 다양한 분야의 논문을 살펴보며 여러 주제에 대한 배경을 쌓고자하는데, 이번에는 Fairness에 대한 연구를 선정하게 되었습니다. 지금 이해한만큼 간단히 설명드리면, 이 논문은 머신러닝 알고리즘을 사용하여 개인과 자원 간의 매칭에서 공정성을 달성하는 방법에 대해 탐구합니다. 특히, 불확실성 하의 공정한 매칭을 위한 새로운 알고리즘 Arand를 제안하며, 이를 통해 공정한 랜덤 할당 알고리즘의 공정성을 정의합니다. 또한, 주어진 공정성 수준에서 주체가 ϕ-fair 즉, Axiom 2를 만족하는 랜덤 할당 알고리즘 Arand를 최대화하는 방법에 대해 논의합니다.  Fairness라는 주제가 최근 많은 관심을 받고 있고, 이를 머신 러닝과 매칭 알고리즘에 어떻게 적용할 수 있는지에 대한 시각을 키워보고자 이 논문을 선택했습니다. 특히, 불확실성 하에서의 공정성을 어떻게 달성할 수 있는지에 대한 접근법은 흥미로운 주제가 될 수 있을 것 같습니다.",
    "url": "https://arxiv.org/abs/2302.03810"
  },
  {
    "date": "2023년 09월 21일",
    "title": "Learnable Graph Convolutional Attention Networks",
    "presenter": "Inwoo Tae",
    "reason": "안녕하세요. 이번에 제가 발표할 논문은 ICLR 2023 virtual presentaion/poster accept된 논문입니다! graph 쪽 관련 논문도 한 번 공부해보고 싶어서 찾아보던 중에 눈에 띄는 제목이 있어서 한 번 간략하게 읽어봤는데 아이디어가 재미있어서 이번 journal club 논문으로 선정했습니다. 아직 저도 완벽하게 읽어보진 못해서 간단하게만 설명해드리면 기존 GAT에서 가지고 있던 noise, 노드 간의 평균 거리, 노드의 연결성 등의 특성에 따라 GAT의 성능이 달라지며 이를 보완하기 위해 CAT(convolutional attention layer)를 제안합니다. convolution을 적용해 주변 노드의 convolution feature에 대한 attention을 계산하는 식입니다. 하지만 상황에 따라서 GCN, GAT, CAT 모델들이 각각 다른 모델들보다 선호될 수 있기 때문에 어떤 모델을 사용할 지 선택하는 것이 어려운 작업이고, 이를 위해 두 개의 학습 가능한 매개변수를 통해 세 모델 사이를 보간하는 L-CAT 모델을 제안합니다. 이를 통해 교차 검증의 필요성 제거되어 비용을 줄일 수 있다는 것이 이 논문의 주요 point 입니다.\n재미있게 읽으시고 다양하게 질문해주시면 감사하겠습니다!",
    "url": "https://arxiv.org/abs/2211.11853"
  },
  {
    "date": "2023년 09월 14일",
    "title": "Explainable Recommendation with Personalized Review Retrieval and Aspect Learning",
    "presenter": "Yejin Kim",
    "reason": "안녕하세요. 미국 3주차 김예진입니다🇺🇸. 저번 Summary journal club에서 ACL’23 Best Papers을 소개해드렸는데요. 그 연장선으로 ACL accepted paper들을 살펴보다가 text generation을 추천에 적용한 논문을 발견해 이번 저널클럽 논문으로 선정해 보았습니다.\nExplainable recommendation은 prediction과 generation tasks를 통합한 테크닉입니다. 그 중 textual generation은 많은 양의 데이터가 있어야 만족스러운 accuracy를 얻을 수 있는데, 추천 데이터의 경우 유저의 history reviews의 양이 충분하지 않은 경우가 있습니다. 이를 해결하기 위해 이 논문에서는 ERRA(Explainable Recommendation by personalized Review retrieval and Aspect learning)라는 새로운 모델을 제안합니다.\nERRA는 크게 두가지 메인 components가 있는데, 첫번째로는 data scarcity를 해결하기 위한 Retrieval enhancement이고 두번째는 관련성 있는 설명을 생성하기 위한 aspect enhancement 입니다. 모델 마지막에는 joint enhancement transformer을 통해 추천점수 예측과 explaination tasks를 수행하였는데, 이를 모두 학습시키기 위해 loss 4개(!!!!)를 합친 multi-task를 수행합니다. Explainable recommendation에 대해 들어보기만 했었는데, 정확히 어떤식으로 모델이 구성 되고 학습되는지에 대해 궁금해서 이 논문을 선택해보았습니다.",
    "url": "https://aclanthology.org/2023.acl-long.4/"
  },
  {
    "date": "2023년 09월 07일",
    "title": "Decision-Focused Learning: Through The Lens Of Learning To Rank",
    "presenter": "Junhyeong Lee",
    "reason": "제가 이번에 고른 논문은 Decision-Focused Learning(DFL)에 관련된 논문이고, 2022 ICML Spotlight를 받은 논문입니다. 지난번에 제가 다룬 Smart \"Predict then Optimize\" 와는 비슷한 연장선에 있으면서도, 새로운 관점을 제시한 논문입니다. Real-World decision making problem은 ML + Combinatory Optimization으로 이루어져 있다고 저자들은 설명합니다. 파라미터들을 예측하고, 최적화 문제를 푸는거죠(SPO 처럼). 여기서 저자들은, Learning to Rank(LTR)의 관점에서 이 framework를 바라본다면, 좀 더 DFL을 generalize 할 수 있다고 주장합니다. 이를 위해 DFL을 위한 새로운 surrogate learning to rank loss function을 제안합니다. 역시 좋은 컨퍼런스에 억셉되려면 이런 loss function을 잘 제안하는 것이 이 분야에서는 매우 중요해 보입니다...저희 연구실에는 이런 나름의 theoretical 측면을 좋아하시는 분들도 있고, 특히 추천시스템 연구하시는 분들은 LTR 논문이나 수식에 익숙 하실 거 같아서 모두 관심 있게 볼 수 있을 만한 논문이라고 생각하여 선정했습니다.",
    "url": "https://arxiv.org/abs/2112.03609"
  },
  {
    "date": "2023년 08월 17일",
    "title": "Stop-loss adjusted labels for machine learning-based trading of risky assets",
    "presenter": "Youngbin Lee",
    "reason": "최근에 저희 연구실에서 출판된 논문인데 FRL이라는 월클 저널에 출판되어서 관심을 갖게 되었습니다. 그리고 제가 참여하고 있는 주식 추천 연구에서 중요한 부분이 투자에서 위험을 고려해 주고 위험 대비 수익을 개선시키는 것이기 때문에 위험 관리 전략에 대해 생각해볼 수 있는 이 논문을 골라 봤습니다.\n이 논문은 주가의 하한선을 미리 정해서 손실을 제한하는 stop-loss trading의 관점에서 주가 예측 모델을 개선시키는 방법을 제안했습니다. 즉, 모델이 stop-loss를 반영해서 예측값을 내뱉도록 labeling을 해 줌으로써 모델 예측(구매 신호)과 실제 의사결정(구매 등 액션)이 일관될 수 있도록 만들어 줍니다.",
    "url": "https://www.sciencedirect.com/science/article/pii/S1544612323006578?casa_token=Z_xmF6yh7ToAAAAA:fSDNWkB_J2MGoyOHOuJoIe6NpaZP0Y7QLpha0jjSCFFPa2WSz_yDGSU9A10NRQ0WlxqDquM54-1U"
  },
  {
    "date": "2023년 08월 17일",
    "title": "Solving Stackelberg Prediction Game with Least Squares Loss via Spherically Constrained Least Squares Reformulation",
    "presenter": "Yoontae Hwang",
    "reason": "최적화관련된 연구입니다. 이런류의 연구들은 보통 저는 훝어보기만 하는데요, 제목이 재밌어 보여서 올려둡니다. 아직 안읽어보긴 했는데, 모티베이션 봤을때  Stackelberg prediction game의 최적화문제가 실제로는 풀기가 꽤 어려워서 시간이 오래걸리고 정확도도 떨어지는데, 이 논문에서는 이런 quadratic fractional programming(QFP)을 빠르고 정확하게 풀도록 spherical constrained least squares(SCLS)하고 원투원이 되도록 파라미터를 잡아서 LSE문제로 쉽게 풀려고 하는것 같습니다. 이 연구는 2022년 ICML outstanding paper로 선정되었습니다.참고로 올해 선정된 2023 ICML outstanding paper에서는 Bayesian Design Principles for Frequentist Sequential Learning 하고 Adapting to game trees in zero-sum imperfect information games 가 재밌어보이네요 ㅎㅎ",
    "url": "https://arxiv.org/abs/2206.02991"
  },
  {
    "date": "2023년 08월 10일",
    "title": "Time Series Change Point Detection with Self-Supervised Contrastive Predictive Coding",
    "presenter": "Seyoung Kim",
    "reason": "Anomaly Detection은 정상 데이터 내에서 비정상적인 데이터 포인트 (outlier, anomaly) 를 탐지하는 기법입니다. 이와 유사하게, 데이터의 패턴이나 추세가 급격하게 변화하는 시점을 탐지하는 Change Point Detection이라는 기법이 있는데, 특히나 시계열 데이터에 많이 적용됩니다. 본 논문은 WWW’21에 accept된 페이퍼로, multivariate time series input을 Contrastive learning을 사용하는 encoder로 representation하여 change point를 탐지하는 방법론을 제시합니다.간략한 메커니즘\n1. 본 논문에서 TS-CP^2라고 이름붙인 모델의 encoder는 기본적으로 TCN 구조이고, input의 window size를 기점으로 이전 데이터와 미래 데이터를 나눈 후 이 데이터들을 negative sampling을 진행합니다. 2.\n2. 그 후 Encoder를 통과해 representation하는 과정에서 contrastive loss를 사용해 positive pairs는 가까이, negative pair는 멀리 학습시킵니다.시계열 데이터에서 단순 이상치 포인트를 탐지한다기 보다는 데이터의 통계적 속성이 급변하는 ‘구간’을 탐지하는 것이 다른 연구에도 좀 더 확장 가능하다는 생각이 들었고, 또 해당 논문에서는 multivariate 데이터도 다루고 있으므로 real world data 특성을 좀 더 고려했다는 생각이 들어서 선택했습니다.",
    "url": "https://dl.acm.org/doi/abs/10.1145/3442381.3449903"
  },
  {
    "date": "2022년 08월 11일",
    "title": "Differentiable convex optimization layer",
    "presenter": "Juchan Kim",
    "reason": "기존에 제시되었던 미분가능한 최적화 문제들은 다양한 세팅에서의 적용이 어렵다는 단점이 있었습니다. 이 논문에서 저자는 컨벡스 최적화 문제를 푸는 방법을 크게 세 가지의 mapping으로 구분하여 제시합니다.\n1. 기존 최적화 문제를 cone programming으로 보내는 mapping\n2. cone programming의 optimal solution을 찾아내는 mapping\n3. cone programming의 optimal solution을 원래 최적화 문제의 optimal solution으로 보내는 mapping저자는 1~3에서 제시한 mapping을 합성함으로써, optimization layer를 구성합니다. 이 때, 각 mapping의 미분가능하다는 좋은 성질들을 이용해, 최적해를 구할 수 있다는 점을 제시하고, 다른 분야에 특화된 optimization layer와 비교했을 때도 실행 시간을 많이 줄일 수 있는 방법론을 제시한다는 점이 흥미로운 논문인 것 같습니다.",
    "url": "https://web.stanford.edu/~boyd/papers/pdf/diff_cvxpy.pdf"
  },
  {
    "date": "2022년 08월 04일",
    "title": "Can machine learning approaches predict corporate bankruptcy? Evidence from a qualitative experimental design",
    "presenter": "Seonmi Kim",
    "reason": "제목을 보고 기업의 파산을 인공지능을 통해서 어떻게 예측하는지 호기심이 생겨 해당 논문을 골라보았습니다. 이 논문에서는 기존의 예측 모델들이 quantitative 데이터를 사용해 훈련시킨 것과 달리 실제로 인간(bankruptcy expert)이 파산을 예측할 때 quantitative 데이터 뿐만 아니라 qualitative 데이터도 쓴다는 점에서 비롯해 여러 신경망 모델들을 qualitative data 를 사용해서 훈련시켜 다양한 실험들을 통해 어떤 모델이 가장 파산을 잘 예측하는지 살펴보는 논문입니다.",
    "url": "https://www.tandfonline.com/doi/epub/10.1080/14697688.2019.1588468?needAccess=true"
  },
  {
    "date": "2022년 08월 04일",
    "title": "Machine-Learning the Skill of Mutual Fund Managers",
    "presenter": "Yongjae Lee",
    "reason": "펀드 매니저의 스킬이라는 것이 실재 하는 것인가에 대한 질문은 재무 분야에서 가장 많이 연구되는 것 중에 하나인데요, 있냐 없냐부터 있으면 얼마나 오래 지속되냐까지 세부적으로 다양하게 나뉘기도 합니다. 이에 대해서 펀드의 특성을 바탕으로 미래에 좋은 성과를 보일 펀드를 머신러닝으로 찾아낼 수 있겠느냐 가능하다면 어떤 특성들이 중요하겠냐 라는 관점의 연구가 나와서 같이 살펴보고자 합니다. 이렇게 재무 또는 개인 금융 데이터에 대한 머신러닝 활용 연구를 제대로 하시는 분들 중 하나인 Stanford의 Kay Giesecke 교수님 논문을 예전에 리뷰 한 적이 있었는데요 (Mortgage risk 관련), 이번에는 좀 더 전통적인 재무 문제(asset pricing, factor, systemic risk)에 관심이 있어보이시는 Markus Pelger 교수님(이분도 Stanford)의 논문입니다.",
    "url": "https://www.nber.org/papers/w29723"
  },
  {
    "date": "2022년 07월 28일",
    "title": "Node2Vec",
    "presenter": "Junpyo Park",
    "reason": "그래프 임베딩 방법론인 Node2Vec을 이해하기 위한 지식들을 정리해 보았습니다.",
    "url": "https://cs.stanford.edu/~jure/pubs/node2vec-kdd16.pdf"
  },
  {
    "date": "2022년 07월 28일",
    "title": "Perceiver IO: A General Architecture for Structured Inputs & Outputs",
    "presenter": "Minjoo Choi",
    "reason": "도메인과 태스크 종류에 구애받지 않고 활용할 수 있는 General-purpose architecture인 Perceiver IO를 소개합니다. 2021년에 발표됐던 Perceiver의 후속작으로 디코더 파트에서 Query를 통해 다양한 종류의 Output 구조에도 대응하도록 학습할 수 있습니다. 트랜스포머에서 쿼리를 적절하게 이용하는 방법을 배울 수 있을 것 입니다.",
    "url": "https://openreview.net/forum?id=fILj7WpI-g"
  },
  {
    "date": "2022년 07월 21일",
    "title": "Neural Tangent Kernel: Convergence and Generalization in Neural Networks",
    "presenter": "안성근",
    "reason": "이 논문에서는 2 hidden layer와 infinite nodes의 neural network를 linear model로 근사할 수 있다고 주장하고, 그 덕분에 문제를 convex하게 만들어 반드시 해가 존재한다는 것을 보여줍니다. nonlinear할 줄만 알았던 NN이 linear한 성분이 있다고 주장하는 것이 흥미로웠고, 인용수도 많은 논문이라고 해서 선택했습니다.",
    "url": "https://arxiv.org/abs/1806.07572"
  },
  {
    "date": "2022년 07월 21일",
    "title": "Unsupervised Representation Learning for Time Series with Temporal Neighborhood Coding",
    "presenter": "Sohyeon Kwon",
    "reason": "시계열 데이터는 다른 데이터들에 비해 길이가 길거나, 차원이 높거나, 빈도가 높기 때문에 이를 나타내는 representation은 효율적이고, 정략적으로 나타낼 수 있어야 하며, 각 sample에 포함된 dynamic changes를 정확하게 학습할 수 있어야 합니다. 본 논문에서는 multivariate non-stationary time series 의 representation 학습을 위해 self-supervised learning framework 인 Temporal Neighborhood Coding (TNC) 를 사용한 방법론을 제안했습니다. TNC는 데이터의 생성 과정 (generative process) 의 local smoothness를 활용하여 시계열의 generalizable representaion을 학습합니다. 시간에 따라 데이터의 latent distribution이 변하는 것을 포착하고, underlying temporal dynamics의 진행양상을 포착할 수 있는 방법론으로, 효율적이고, 고차원의 데이터에도 활용할 수 있다는 점이 장점입니다. 논문에서는 의학 시계열에서 문제점을 야기하면서 시계열 representation learning 의 어려움을 제기하지만, 여러 시계열에도 실험을 하고, 다른 unsupervised representation learning 보다 더 좋은 성능을 보이고, 본 방법론을 통해 얻은 representation으로 classification 및 clustering 을 했을 때 더 좋은 성능을 낸다는 것을 확인하였습니다.",
    "url": "https://openreview.net/forum?id=8qDwejCuCN"
  },
  {
    "date": "2022년 07월 14일",
    "title": "Factor momentum and Regime-Switching Overlay Strategy",
    "presenter": "Seyoung Kim",
    "reason": "최근 미국의 금리 인상으로 인해 국내 증시가 폭락한 상황이 연일 이어지고 있고, 이는 market crash 현상으로 볼 수 있습니다. 투자자들은 이러한 시장 위기 상황에서도 위험을 분산시키고 자산을 보호하고 싶지만, 쉽지 않은 가운데 본 논문은 market regime 정보를 포트폴리오에 반영한 time-series factor momentum 전략을 통해 위기 상황에서도 수익률을 잘 방어하는 모델을 제안합니다. market regime information을 측정하고 switching을 예측하기 위해 사용한 머신러닝 기법들을 알아보고, 다양한 벤치마크 시뮬레이션을 통해 factor momentum의 효과에 대해서도 살펴보기 좋을 것 같아 선택했습니다.",
    "url": "https://jfds.pm-research.com/content/3/4/101"
  },
  {
    "date": "2022년 07월 14일",
    "title": "SAINT: Improved neural networks for tablular data via row attention and contrastive pre-training",
    "presenter": "Youngbin Lee",
    "reason": "정형 데이터에서 트리 기반 모델을 이기기 위해 디자인한 딥러닝 기반 모델입니다. attention과 self supervised pre-training을 이용한 구조를 가지고 있는 예측 모델입니다. 실험결과는 XBG, LGBM같은 트리 부스팅 모델들과 TabNet, TabTrasformer 등 정형 데이터용 딥러닝 모델과 비교합니다.\n금융 관련 데이터로 정형 데이터를 주로 사용하게 될 거고, 또 모델 구조에 attention, embedding, pre-training & fine-tuning, layer normalization, GLU 등등 딥러닝 관련해서 알아두면 좋을 개념들이 많은 것 같아서 골랐습니다.\n(ICLR 2022 conference paper에 리뷰 중인 논문입니다)",
    "url": "https://arxiv.org/abs/2106.01342"
  },
  {
    "date": "2022년 07월 07일",
    "title": "Averaging Weights Leads to Wider Optima and Better Generalization",
    "presenter": "Yoontae Hwang",
    "reason": "SWA를 모두 알아두면 좋을것 같아 골랐습니다",
    "url": "https://arxiv.org/pdf/1803.05407.pdf"
  },
  {
    "date": "2022년 06월 29일",
    "title": "Covariance Matrix Estimation under Total Positivity for Portfolio Selection",
    "presenter": "안성근",
    "reason": "금융인공지능과목을 수강하고, 논문을 찾던 중 Markowitz portfolio가 나와서 반가워서 골랐습니다. Markowitz portfolio theory에서 만들어진 포트폴리오의 분산을 구할 때, 공분산 행렬을 구한 뒤 각 항을 모두 더합니다. 이 논문에서는 asset끼리 서로 긍정적으로 dependent한다는 점을 활용해 MTP2(multivariate totally positive of order 2)의 분포를 고려해서 공분산 행렬을 추정합니다.",
    "url": "https://academic.oup.com/jfec/article/20/2/367/5902421"
  },
  {
    "date": "2022년 06월 29일",
    "title": "QuantNet: transferring learning across trading strategies",
    "presenter": "Seonmi Kim",
    "reason": "보통 트레이딩 전략을 세울 때 해당하는 마켓의 특성만 고려하여 세우는 경우가 많은데 각각의 마켓은 고립되었다기보다는 마켓끼리 서로 영향을 주고 받을때도 있어 local과 global 트렌드를 둘 다 반영한 트레이딩 전략을 세워야한다고 저자는 주장합니다. 이에 transfer learning을 통해서 특정 마켓에 한정된 트렌드 뿐만 아니라 여러 마켓 전반에 나타나는 트렌드 또한 반영해서 이를 트레이딩 전략 학습에 사용하는 방법을 제안하고 있습니다. ",
    "url": "https://www.tandfonline.com/doi/pdf/10.1080/14697688.2021.1999487?needAccess=true"
  },
  {
    "date": "2022년 06월 09일",
    "title": "Sequential Neural Processes",
    "presenter": "Minjoo Choi",
    "reason": "NP는 분포의 Meta-learning과 Stochastic Process를 이용해 기존의 Supervised learning에서 잘 다루지 못하는 Small data regime과 예측의 Uncertainty 측정 등 두 영역을 해결하려고 합니다. 2018년에 https://arxiv.org/pdf/1807.01622.pd.이 처음 발표한 NP는 stochastic process의 temporal dynamics를 잘 반영하지 못하는데요, 본 페이퍼에서 RNN을 이용한 State-space 모델을 통해 이 문제를 해결하고자 했습니다.저널클럽에서는 NP에 대해서도 리뷰해보려고 합니다.",
    "url": "https://papers.nips.cc/paper/2019/file/110209d8fae7417509ba71ad97c17639-Paper.pdf"
  },
  {
    "date": "2022년 05월 26일",
    "title": "Accurate Multivariate Stock Movement Prediction via Data-Axis Transformer with Multi-Level Contexts",
    "presenter": "Sohyeon Kwon",
    "reason": "이 논문은 2021 KDD 에 accept 된 페이퍼로 Transformer 를 기반으로 주가를 예측하는 모델입니다.\n시계열 예측 task는 머신러닝/딥러닝 분야에서 흔하게 다루어지는 task 입니다. 주가는 대표적인 시계열 중 하나이지만, 기온이나 교통 데이터와는 다르게 기본적으로 random movement 가 많이 포함되어 있기 때문에 다른 시계열 예측 task 에 비해서는 까다롭게 여겨지는 편입니다.\n이 논문에서는 주가 예측 모델로 DTML (Data-axis Transformer with Multi-Level contexts) 라는 모델을 제안하는데, 여러개의 주식 종목들을 자동으로 연관지어서 주가 예측에 사용하는 것이 큰 아이디어 입니다.",
    "url": "https://dl.acm.org/doi/10.1145/3447548.3467297"
  },
  {
    "date": "2022년 05월 19일",
    "title": "Index tracking through deep latent representation learning",
    "presenter": "Yongjae Lee",
    "reason": "인덱스 펀드를 만들거나 할 때 보통 인덱스를 구성하는 모든 종목을 다 가지고 할 수는 없기 때문에 일부 종목을 골라서 weight를 조정해가면서 해당 index를 tracking 하는 portfolio를 만들게 됩니다. 예전에는 주로 optimization approach가 많이 쓰였지만, 시계열 클러스터링이나 차원축소 기법 등을 사용하는 방법들도 제안이 되고 있습니다. 그 중에서 이 논문은 최근에 autoencoder의 reconstruction loss가 작은 종목들을 골라서 아주 단순한 weighting scheme만 사용해도 웬만큼 index tracking이 된다는 연구의 extension인데, 접근법은 정말정말 단순합니다. 하지만 잘 생각해보면 이 부류의 접근법은 market index를 tracking 할 때에만 잘 먹히고, customized index에는 적용이 어렵습니다. 우리 연구실이 앞으로 direct indexing 관련한 프로젝트와 연구를 하게 될 것 같기 때문에 관련 내용을 소개 하고 여러 아이디어를 앞으로 만들어나갈 수 있는 계기가 되었으면 좋겠어서 정말 단순한 논문임에도 불구하고 골라봤습니다.",
    "url": "https://www.tandfonline.com/doi/full/10.1080/14697688.2019.1683599"
  },
  {
    "date": "2022년 05월 13일",
    "title": "The PageRank Citation Ranking: Bringing Order to the Web",
    "presenter": "Junpyo Park",
    "reason": "구글은 시가 총액 1.5조 달러의 기업(2022-04-28 기준 market cap, 세계 4위)으로 전 세계 검색량의 90% 이상을 점유하고 있으며 1998년 래리 페이지와 세르게이 브린에 의해 설립되었습니다.\n이 구글의 시작이 된 논문이 두 설립자가 쓴 https://storage.googleapis.com/pub-tools-public-publication-data/pdf/334.pdf 라는 페이퍼인데 In this paper, we present Google, a prototype of a large-scale search engine which makes heavy use of the structure present in hypertext. 라는 문구로 abstract가 시작합니다. 해당 논문의 2.1절을 보면 link로 연결된 Web 구조(그래프 스트럭쳐)에 적합한 ranking인 페이지 랭크를 사용한다는 언급과 페이지 랭크에 대한 간단한 소개가 있습니다.\n이 페이지 랭크를 자세히 소개한 논문이 이번에 발표할 논문 http://ilpubs.stanford.edu:8090/422/1/1999-66.pdf 입니다. (웹 페이지의 페이지 그리고 저자의 이름 래리 페이지의 페이지의 이름을 따서 알고리즘 이름을 지었다는 썰이 있는데 맞는지는 잘 모르겠습니다... ) 지금의 구글 검색 알고리즘은 엄청나게 많은 다른 요소를 고려하여 고도화되었기 때문에 이것보다 훨씬 복잡하지만 \"영향력 있는 페이지가 인용할수록 페이지랭크가 올라간다\"는 근본적인 알고리즘은 그대로 남아 있다고 합니다.\n그동안 제 관심분야인 그래프 딥러닝, 추천 관련 논문만 발표했던 것 같아 쫌 연식이 있긴 하지만 다같이 알면 좋은 만한 페이퍼로 준비해 보았습니다.",
    "url": "http://ilpubs.stanford.edu:8090/422/1/1999-66.pdf"
  },
  {
    "date": "2022년 04월 28일",
    "title": "Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning",
    "presenter": "Seyoung Kim",
    "reason": "딥러닝에서 모델의 overfitting을 방지하는 regularization 방법인 Dropout을 Bayesian Neural Net 처럼 생각할 수 있다는 방법론입니다. regression이나 classification 문제에서 모델의 uncertainty를 capture하는 것은 매우 중요한 문제인데, 본 페이퍼에서는 모델의 dropout을 Bayesian Approximation을 이용한 Deep Gaussian Process로 근사하여 방대한 계산 비용 없이 uncertainty를 estimate할 수 있다는 주장입니다. Uncertainty modeling을 하는 방법론들에 대해 흥미가 생겨 저널클럽 주제로 선택했습니다.",
    "url": "https://arxiv.org/abs/1506.02142"
  },
  {
    "date": "2022년 04월 14일",
    "title": "The economic value of NFT - Evidence from a protfolio analysis using mean-variance framework",
    "presenter": "Youngbin Lee",
    "reason": "전통적인 자산으로 이루어진 포트폴리오에 디지털 자산인 NFT를 포함시켰을 때 diversification benefit 을 연구한 논문입니다.\n1) NFT의 특성\n2) NFT (혹은 디지털 자산) 을 활용한 투자\n두 가지에 대해 배울 수 있을 것 같습니다.",
    "url": "https://www.sciencedirect.com/science/article/pii/S1544612322000976#b9"
  },
  {
    "date": "2022년 04월 07일",
    "title": "Anomaly transformer : Time series anomaly\ndetection with association discrepancy(2022)",
    "presenter": "Yoontae Hwang",
    "reason": "다음주 저널클럽은 Anomaly Transformer를 살펴보도록 하겠습니다. Association Disrepancy를 Local한 부분과 Global한 구분으로 구분하여 정의하고, 이를 동시에 구현하기 위해  Anomaly Transformer를 제안하였습니다. 이 때 Local한 부분은 가우시안 커널을 이용하여 인근의 point의 변화를 살펴보고, global한 부분은 attention을 통해 살펴보고 각각의 Association을 잘 반영하기 위하여 minmax optimization을 사용합니다.",
    "url": "https://arxiv.org/abs/2110.02642"
  },
  {
    "date": "2022년 03월 24일",
    "title": "Calibrating Probability with Undersampling for Unbalanced Classification",
    "presenter": "김연수",
    "reason": "저널클럽 10번째 주제였던 On Calibration of Modern Neural Networks 논문을 읽고 Calibration 문제가 데이터가 불균일한 상황에서 발생한다는 생각이 들었는데 관련 논문을 찾을 수 있었습니다. 논문에서 극단적인 class imbalance dataset의 예시로 credit-card fraud 데이터를 사용하기도 했습니다.\nBayes Minimun Risk theory를 바탕으로 데이터셋을 언더샘플링 하고 이진 분류 문제의 정확도를 향상시킵니다. well-calibrated classifier는 이상 탐지에서의 결정 시스템에 중요한 영향을 미치는 요인 중 하나이기에 해당 논문을 선정하였습니다.\n딥러닝 모델이 아니라 통계적인 방법을 다루는 페이퍼이고, 직접적인 관련이 있는건 아니지만 이상치를 감지한다는 아이디어만 따와서 한가지 실험을 해보려고 합니다.\n내부자거래로 징계받은 기업의 일간 거래량 데이터를 바탕으로 이상거래를 탐지할 수 있는지 확인하는 실험을 계획했습니다. '거래량이 평소보다 많아지면 수상하다'에서 그치는게 아니라, 뭔가 의미있는 정보를 찾을 수 있을지 알아보고 싶습니다.",
    "url": "https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7376606"
  },
  {
    "date": "2022년 03월 17일",
    "title": "A New Approach to Markov-Switching GARCH Models",
    "presenter": "안성근",
    "reason": "시계열 수업 마지막에 가르쳐주신 GARCH에 대한 공부가 더 필요할 것 같았습니다. 이 논문에서는 GARCH 모델의 문제를 해결하면서 기존 모델 추정에 대한 어려움, 동적 특성에 대한 이해가 잘 되지 않는 점을 개선했다기에 다시 공부하면서 알아보고자 이 논문을 선정하였습니다.",
    "url": "https://academic.oup.com/jfec/article/2/4/493/900480"
  },
  {
    "date": "2022년 03월 10일",
    "title": "Learning Representations for Time Series Clustering",
    "presenter": "Seonmi Kim",
    "reason": "시계열 군집화의 방식 중 하나인 특성 추출 기반 방식은 실제 시계열 데이터에서 많이 나타나는 non-linear dynamics 를 찾아내지 못하는 경우가 많아 cluster specific representation 을 잘 생성하지 못하는 문제점이 있습니다. 이러한 문제점을 해결하고자 이 논문에서는 Temporal reconstruction과 k means objectives를 seq2seq 모델에 결합한 Deep Temporal Clustering Representation 모델을 사용해서 더 나은 cluster specific representation을 만드는데, 이 과정에서 encoder 의 성능을 높이기 위해 fake-sample generation 전략을 쓰고 auxiliary classification task을 도입하는 부분이 흥미로워 저널클럽 논문으로 선정하였습니다.",
    "url": "https://papers.nips.cc/paper/2019/hash/1359aa933b48b754a2f54adb688bfa77-Abstract.html"
  },
  {
    "date": "2022년 02월 25일",
    "title": "Adversarial Sparse Transformer for Time Series Forecasting",
    "presenter": "Sohyeon Kwon",
    "reason": "시계열 예측에는 많은 접근 방법이 있는데, 이 접근 방법들에서 흔하게 발견되는 두가지 한계점이 있습니다. 첫번째로, 유연성 (flexibility)가 없이 정확한 값만을 예측한다는 것이고, 두번째로, auto-regressive generative mode 에 기반한 예측 모델들은 데이터를 생성하는 과정에서 현재 시점까지 생성한 데이터에 기반하여 다음 값을 생성하기 때문에 error accumulation이 일어나게 됩니다. 본 논문에서는 이를 해결하기 위해 Generative Adversarial Networks (GANs) 에 기반한 Adversarial Sparse Transformer 모델을 제안합니다. AST 모델은 Sparse transformer 를 generator로 하여 시계열 예측을 위한 sparse attention map을 학습하고 discriminator로 예측 성능을 개선하도록 학습합니다. GAN 이라는 프레임워크에 다양한 모델을 사용함으로써 단순히 생성모델을 넘어서 예측 모델로 확장을 시킨다는 점이 흥미로워서 선정하였습니다.",
    "url": "https://proceedings.neurips.cc/paper/2020/hash/c6b8c8d762da15fa8dbbdfb6baf9e260-Abstract.html"
  },
  {
    "date": "2022년 02월 25일",
    "title": "HiTANet: Hierarchical Time-Aware Attention Networks for Risk Prediction on Electronic Health Records",
    "presenter": "Minjoo Choi",
    "reason": "개인적으로 여러 실험으로 모델 설계와 가정을 정당화 시키는 과정이 인상적이었습니다.\n• 질병의 진행(Disease Progression)정도는 개인의 치료 결과에 큰 영향을 미칩니다.\n• 현재 질병의 위험도를 예측하는 모델을 만들 때 질병의 진행(Disease progression)은 Stationary 하다는 강한 가정을 이용하는데, 실제 질병의 진행은 Non-stationary 합니다.\n• 본 페이퍼에서는 질병의 위험을 시간 정보(Time information)에 따라 모델링 할때 그 전의 정보를 단순 감쇄 하지 않고 Local과 Global, 두 종류의 어텐션 가중치를 사용해 과거의 일부 정보(사건)가 현재의 위험도를 상승하는데 기여하도록 합니다.\n•  의료 비용 또한 질병의 진행에 따른 위험도에 의해 급격히 증가할 수 있기 때문에 본 모델로 모델링이 가능할 것 같아 저널클럽 논문으로 선정하였습니다.",
    "url": "https://dl.acm.org/doi/10.1145/3394486.3403107"
  },
  {
    "date": "2022년 02월 16일",
    "title": "Deep Learning for Mortgage Risk",
    "presenter": "Yongjae Lee",
    "reason": "Management Science의 finance department editor 중 한 분인 Stanford의 Kay Giesecke 교수님 논문인데요, 이 교수님이 금융 시스템이나 개인 금융 데이터에 딥러닝 적용하는 연구를 많이 하셔서 평소에 관심을 두고 있었고요, 이 참에 그 중에 하나를 리뷰 해보면 좋겠다는 생각이 들어서 골랐습니다. 미국에서 약 20여년간 담보대출을 받은 사람들의 데이터를 딥러닝으로 분석하여 어떤 변수들이 어떻게 영향을 미치는지에 대해 이야기 하고 있습니다. 저희 연구실에서 진행하는 여러 연구에서 참고가 많이 될 것 같습니다. 논문이 좀 길어서 주요 내용 위주로 추려서 소개하도록 하겠습니다.",
    "url": "https://academic.oup.com/jfec/article/19/2/313/6329869?login=true"
  },
  {
    "date": "2022년 02월 15일",
    "title": "Autoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting",
    "presenter": "Yoontae Hwang",
    "reason": "NeurIPS 2021 Poster로 억셉된 페이퍼입니다. 장기예측에서 계절요인과 트렌드요인을 반영하여, 이 분야에서 가장 SOTA model인 informer보다 훨씬 더 좋은 성능을 기록했습니다. 기본적인 컨셉은 informer와 비슷하지만 시계열적인 요인들을 잘 고려한것이 인상 깊었습니다.",
    "url": "https://arxiv.org/abs/2106.13008"
  },
  {
    "date": "2022년 02월 08일",
    "title": "Robust Anomaly Detection for Multivariate Time Series through Stochastic Recurrent Neural Network",
    "presenter": "Seyoung Kim",
    "reason": "기존의 multivariate time series에서 anomaly detection 하는 방법은 그들의 temporal dependency와 stochastic한 성질을 잘 고려하지 못한다는 단점이 있었으나, 본 논문에서 제시하는 OmniAnomaly라는 방법을 통해 두 성질 모두를 고려함으로써 기존 방법의 한계를 보완한다고 합니다. 본 논문에서 사용되는 multivariate time-series 들은 대부분 industry에서 쓰이는 devices들로, financial time series와는 다를 수 있지만 anomaly score를 도출하는 방법에 대해 궁금증이 생겨서 선택했습니다.",
    "url": "https://dl.acm.org/doi/10.1145/3292500.3330672"
  },
  {
    "date": "2022년 02월 08일",
    "title": "On Calibration of Modern Neural Networks",
    "presenter": "Youngbin Lee",
    "reason": "딥러닝 모델을 실제 의사결정에 활용하고자 할 때, 예측 정확도도 중요하지만 모델이 정확한 uncertainty를 제공하는 것 역시 중요합니다.\n만약 어떤 분류모델이 내뱉은 출력값 (confidence) 이 실제로 정답일 확률 (accuracy) 와 일치한다면, 우리는 그 모델을 신뢰할 수 있습니다.\n모델의 출력값과 정확도가 일치하도록 보정하는 것을 calibration 이라고 합니다. 그리고 이 논문에서는 효과적인 calibration을 위한 방법으로 temperature scaling을 제안합니다.\n이미지 분류 모델을 학습시키는 코드를 공부해 보기 위해 이 논문을 골랐습니다. 논문에서 제안하는 방법론은 간단하기 때문에, 코드를 공부한 내용도 함께 발표해 볼 예정입니다.",
    "url": "https://arxiv.org/abs/1706.04599"
  },
  {
    "date": "2022년 01월 25일",
    "title": "Metcalfe’s Law as a model for Bitcoin’s Value",
    "presenter": "Minjoo Choi",
    "reason": "비트코인의 가치를 네트워크 이론의 Metcalfe's Law를 이용해서 구해본 논문입니다. 암호화폐를 어떻게 밸류에이션 할지 고민해볼수 있는 논문인 것 같아서 골랐습니다.",
    "url": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3078248"
  },
  {
    "date": "2022년 01월 25일",
    "title": "BPR: Bayesian Personalized Ranking from Implicit Feedback",
    "presenter": "Junpyo Park",
    "reason": "저번 발표에서 User와 Item 사이의 관계를 모델링하는 기법인 Collaborative Filtering (MF, NCF, NGCF)에 대해 다루었습니다. CF에서 ‘클릭’, ‘구매’ , ‘시청’ 등과 같이 user의 선호가 분명하게 드러나지 않는 데이터를 implicit-data라 하는데 implicit-data의 주요 특징중 하나는 부정적인 데이터가 관측되지 않는다는 점(unary-variable, not binary) 입니다.\n\n따라서 관측되지 않은 데이터에 대해서는 실제로 user가 관심이 없는 것(real negative feedback)인지, 아니면 관심이 있지만 아직 모르는 것(missing value) 인지가 구분되지 않습니다. 따라서 이 두가지 경우를 모두 고려하여 personalized ranking 을 구하는 방법을 소개하고자 본 논문을 선택하였습니다.",
    "url": "https://arxiv.org/abs/1205.2618"
  },
  {
    "date": "2022년 01월 18일",
    "title": "Adjusting for Autocorrelated Errors in Neural Networks for Time Series",
    "presenter": "Sohyeon Kwon",
    "reason": "시계열의 Maximum likelihood estimation에 기반한 Neural network은 흔히 각 시점의 error가 uncorrelated 되어 있다고 가정을 합니다. 그러나, 대부분의 경우 error는 autocorrelated 되며, 이러한 경우는 흔히 가정하는 maximum likelihood estimation의 정확도를 떨어뜨립니다. 본 논문에서는 autocorrelated error를 조정하기 위해 autocorrelation coefficient를 모델의 parameter와 함께 학습하도록 하며, 넓은 범위의 시계열 데이터를 다양한 모델에 적용시켜 새로 제안한 방법론을 사용함으로써 모델의 성능이 좀 더 강건해지고, 모델이 좀 더 효과적으로 학습을 한다는 것을 보여주고 있습니다.",
    "url": "https://papers.nips.cc/paper/2021/hash/f8e6ba1db0f3c4054afec1684ba8fb26-Abstract.html"
  },
  {
    "date": "2022년 01월 18일",
    "title": "Do AI-powered mutual funds perform better?",
    "presenter": "Yongjae Lee",
    "reason": "최근에 비슷한 맥락의 논문들이 연달아 publish가 되길래 한번 살펴보고 정리를 해보면 좋겠다 싶어서 골라봤습니다. 이거는 일단 AI를 사용한다고 하는 mutual fund 들의 performance가 어땠는지를 분석한 논문이고요, 비슷한 시기에 machine learning을 사용하는 quant fund에 대해 분석한 논문도 있어서 같이 간단하게 살펴보고자 합니다. 살펴보는 김에 역시나 최근에 나온 AI ETF들이 underlying stock에 미치는 영향에 대한 논문도 있어서 거기까지 간단히 살펴보겠습니다.",
    "url": "https://www.sciencedirect.com/science/article/pii/S1544612321005547"
  },
  {
    "date": "2022년 01월 11일",
    "title": "Temporal Difference Variational Auto-Encoder",
    "presenter": "Yoontae Hwang",
    "reason": "이 페이퍼 Figure 4에 Skip-state prediction for 1D signal 결과를 보고 매우 흥미로워 보여서 선택하게 되었습니다.",
    "url": "https://openreview.net/pdf?id=S1x4ghC9tQ"
  },
  {
    "date": "2022년 01월 11일",
    "title": "Dynamic Portfolio Optimization Across Hidden Market Regimes",
    "presenter": "Seyoung Kim",
    "reason": "Model Predictive Control (MPC) 라는 방법을 통해 기존의 Market regime 기반 연구에서 쓰이는 static decision rule 보다 더 좋은 성과를 내고 dynamic한 optimization을 할 수 있다는 점에서 배울 점이 많을 것 같아 본 논문을 고르게 되었습니다.",
    "url": "https://www.tandfonline.com/doi/abs/10.1080/14697688.2017.1342857"
  },
  {
    "date": "2022년 01월 04일",
    "title": "Alternative Data in Investment Management: Usage, Challenges, and Valuation",
    "presenter": "Youngbin Lee",
    "reason": "기관 투자자들이 포트폴리오 수익을 높이기 위해 기존에 고려되지 않았던 비재무적 정보 (대체 데이터, Alternative data)를 점점 더 많이 활용하고 있다고 합니다.\n금융 데이터 분석이라는 큰 주제 안에서 연구하고 있기 때문에, 다양한 종류의 데이터가 투자에 활용되는 방식을 알아 두면 도움이 될 것 같아서 골랐습니다",
    "url": "https://jfds.pm-research.com/content/3/4/10"
  },
  {
    "date": "2022년 01월 04일",
    "title": "Neural Graph Collaborative Filtering",
    "presenter": "Junpyo Park",
    "reason": "그래프 기반의 추천 시스템 연구를 시작하면서 근본(?)이 되는 페이퍼를 선정하게 되었습니다. 추천 시스템에 대해 간단히 소개하고 Collaborative Filtering 의 여러 모델들(MF, NCF, NGCF)을 차례대로 살펴보며 발전 과정을 이해 할 수 있도록 자료 만들었습니다.",
    "url": "https://arxiv.org/abs/1905.08108"
  },
  {
    "date": "2021년 12월 07일",
    "title": "Focusing on the worst state for robust investing",
    "presenter": "Seyoung Kim",
    "reason": "시장 상황이 최악인 경우에 어떻게 하면 robust optimization을 이룰 수 있는지에 대해서 궁금했습니다. 또한 Market의 state에 따라 다르게 나타나는 포트폴리오 수익률이 AICP에서 GAN의 Discriminator Score를 분위별로 나누어 수익률을 비교하는 방법에 참고하기 좋을 것 같아서 본 논문을 선택했습니다. ",
    "url": "https://doi.org/10.1016/j.irfa.2015.02.001"
  },
  {
    "date": "2021년 11월 30일",
    "title": "The Neural Hawkes Process: A Neurally\nSelf-Modulating Multivariate Point Process",
    "presenter": "Yoontae Hwang",
    "reason": "혹스 프로세스를 LSTM 레이어를 이용해 우도를 근사한 연구입니다",
    "url": "https://arxiv.org/abs/1612.09328"
  },
  {
    "date": "2021년 11월 23일",
    "title": "Predictably Unequal? The Effects of Machine Learning on Credit Markets",
    "presenter": "Yongjae Lee",
    "reason": "Journal of Finance에 최근 accept된 논문인데요, 제가 검색해본 결과로는 JF에서 처음으로 제목에 machine learning이 들어간 논문입니다. 본문만 60페이지 정도 되고, 부록 포함하면 70 페이지 짜리라서 많은 고민이 되었지만 그래도 나름 큰 의미가 있는 논문이니 주요 내용만 간단히 훑어보는 것으로 하도록 하겠습니다..",
    "url": "https://onlinelibrary.wiley.com/doi/abs/10.1111/jofi.13090"
  },
  {
    "date": "2021년 11월 16일",
    "title": "Decision Transformer: Reinforcement Learning via Sequence Modeling",
    "presenter": "Sohyeon Kwon",
    "reason": "Decision Transformer 는 causally masked transformer를 이용하여 RL의 문제들을 sequential modeling으로 바꾼다는 내용입니다. RL을 이용하여 Sequential modeling을 통해 여러 문제들을 풀 수 있다는 점이 흥미로워서 골랐습니다. 당연하게도 논문에 강화학습과 Transformer에 대한 내용이 기반인 부분이 많은데, 이 내용은 이전에 제가 Set Transformer와 Improving GAN training with probability ratio clipping and sample reweighting 논문 리뷰를 진행할 때 모두 소개했던 개념들이라 따로 소개하지는 않겠습니다.",
    "url": "https://arxiv.org/abs/2106.01345"
  },
  {
    "date": "2021년 11월 02일",
    "title": "GROKKING: GENERALIZATION BEYOND OVERFITTING\nON SMALL ALGORITHMIC DATASETS",
    "presenter": "Youngbin Lee",
    "reason": "신경망 모델을 아주 오랫동안 학습시키면 무슨 일이 일어날까? 를 실험한 논문입니다.\n\"grokking\" (신경망을 과적합되는 지점보다 훨신 더 많이 훈련시켰을 때, 일반화 성능이 다시 점점 좋아지는 현상) 이 왜 발생하고 어떻게 가능한지를 설명합니다.\n과적합과 일반화에 관한 상식과 반대되는 현상이 흥미로워 보여서 골랐습니다.",
    "url": "https://mathai-iclr.github.io/papers/papers/MATHAI_29_paper.pdf?fbclid=IwAR3QB_ncXVCEudsg1GU4IOV-zafAfDewBSswSRWGKzJZj5i4_8fVCDkVdX8"
  },
  {
    "date": "2021년 10월 26일",
    "title": "Recurrent Marked Temporal Point Processes:\nEmbedding Event History to Vector",
    "presenter": "Minjoo Choi",
    "reason": "우리는 다양한 사건(이벤트, Event)에 대한 예측 모델을 만들 때, 그 사건이 생성되는 과정에 대한 가정을 해야 합니다.  본 논문은 이벤트 데이터의 역학(Dynamics)에 대한 강한 가정 없이 몇 가지 종류(k개)의 이벤트가 있다고 할 때, 한 사람의 이벤트 시퀀스(t,k)를 예측하는 문제를 풀고자 합니다.  이러한 모델을 Recurrent Marked Temporal Point Process라 합니다.",
    "url": "https://www.kdd.org/kdd2016/papers/files/rpp1081-duA.pdf"
  },
  {
    "date": "2021년 10월 12일",
    "title": "COVID-19 Pandemic and Investor Herding Behavior",
    "presenter": "Junpyo Park",
    "reason": "코로나 구간에서의 투자자 군집행동(Herding behavior)을 CSAD라는 지표를 활용해 분석한 연구 입니다. 군집행동을 정의하고 팬데믹 기간에 군집행동이 있었는지 있었다면 어떤 요인 때문에 생긴것인지 분석합니다. 분석 결과 대형주 효과와 공포지수가 투자자의 군집행동에 영향을 끼쳤다고 설명하고 있습니다.",
    "url": "http://journal.dcs.or.kr/xml/29959/29959.pdf"
  },
  {
    "date": "2021년 10월 05일",
    "title": "LEARNING WITH FEATURE-DEPENDENT LABEL NOISE:\nA PROGRESSIVE APPROACH",
    "presenter": "Yoontae Hwang",
    "reason": "시간이 변경되어서 논문을 변경합니다. outlier detection 관련해서 영감을 받은 논문이 있는데 이걸 소개하고 이상치탐지에 노벨티하게 접근하는것을 봅시다 ",
    "url": "https://arxiv.org/abs/2103.07756"
  },
  {
    "date": "2021년 09월 14일",
    "title": "Practical Bayesian Optimization of Machine Learning Algorithms",
    "presenter": "Seyoung Kim",
    "reason": "미래에셋 대회 준비에 쓰이는 GAN 모델의 hyperparameter tuning을 함에 있어 grid search, random search 등의 방법론들을 알아보다가 bayesian optimization에 대해 알게 되었고, 알아두면 좋을것 같아서 본 논문을 선택하게 되었습니다.",
    "url": "https://papers.nips.cc/paper/2012/file/05311655a15b75fab86956663e1819cd-Paper.pdf"
  },
  {
    "date": "2021년 09월 07일",
    "title": "Currency Factors",
    "presenter": "Yongjae Lee",
    "reason": "클러스터링을 통해서 G10 국가들의 currency 사이의 factor를 찾아보고 분석해보는 연구입니다. 최근에 MS에 억셉 된 논문인데 흥미로워보여서 골라봤습니다.",
    "url": "https://pubsonline.informs.org/doi/abs/10.1287/mnsc.2021.4023"
  },
  {
    "date": "2021년 08월 19일",
    "title": "Interpretable Deep Models for ICU Outcome Prediction",
    "presenter": "Minjoo Choi",
    "reason": "Knowledge-distillation 방법을 통해 해석가능한 모델을 만드는 과정을 소개하려고 합니다. 적용 도메인은 의료보험에서 다루는 EHR, 헬스케어 입니다.",
    "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5333206/"
  },
  {
    "date": "2021년 08월 19일",
    "title": "TabNet: Attentive Interpretable Tabular Learning",
    "presenter": "Youngbin Lee",
    "reason": "TabNet은 tabular 데이터를 위한 딥러닝 모델입니다. 부스팅 모델만큼 좋은 예측성능을 낼 수도 있고 변수 중요도를 파악할 수 있다는 장점이 있습니다. 정형 데이터로 예측모델을 만드는 BTS 연구에 참고할 수 있을 것 같아 이 논문을 선택했습니다.",
    "url": "https://arxiv.org/abs/1908.07442"
  },
  {
    "date": "2021년 08월 12일",
    "title": "Trading via Image Classification",
    "presenter": "Junpyo Park",
    "reason": "트레이더들은 일반적으로 캔들 차트(이미지)를 보고 매매 의사결정을 내리는데 이런 매매 rule을 ML/DL 모델이 학습할 수 있는지에 대한 의문에서 시작된 논문입니다. 이미지 데이터(캔들차트)에 기술적 지표를 활용한 간단한 룰을 통해 레이블링을 하여 이런 매매 Rule을 잘 학습하는지 확인해본 논문입니다. 실제 implementation도 쉬워 보여서 간단하게 실험해본 결과 까지 설명할 예정 입니다.",
    "url": "https://arxiv.org/abs/1907.10046"
  },
  {
    "date": "2021년 08월 12일",
    "title": "Improving GAN Training with Probability Ratio Clipping and Sample Reweighting",
    "presenter": "Sohyeon Kwon",
    "reason": "Wasserstein distance 와 Lipschitz continuity 를 활용하여 GAN 훈련을 향상시키는 것 처럼 probability ratio clipping 과 sample reweighting 을 이용하여 GAN 훈련을 향상시킨다는 내용입니다. 해당 논문에서는 text generation과 image generation, text style transfer 분야에 활용하고 있으나 추후 연구에 사용할 수 있을 것 같아서 골라보았습니다. 논문에 WGAN과 Reinforcement Learning 에 대한 내용이 많이 포함되어 있으니 개념정도는 보고 오시는 것이 좋을것 같습니다.",
    "url": "https://arxiv.org/abs/2006.06900"
  },
  {
    "date": "2021년 08월 05일",
    "title": "Maxing Out Globally: Individualism, Investor Attention, and the Cross Section of Expected Stock Returns",
    "presenter": "Yongjae Lee",
    "reason": "투자자들이 고점이 높은 (with positive extreme return) 주식에 좀 더 몰리는 경향이 있다는 내용입니다. 개인주의가 얼마나 강한지에 따라 국가별로 그 현상이 어떻게 다르게 나타나는지도 분석을 하고 있습니다. 주제가 흥미롭기도 하고 여러 아이디어를 얻을 수도 있을 것 같아서 골라봤습니다.",
    "url": "https://pubsonline.informs.org/doi/abs/10.1287/mnsc.2017.2830"
  },
  {
    "date": "2021년 08월 05일",
    "title": "PAGAN : Portfolio Analysis with Generative Adversarial Networks",
    "presenter": "Seyoung Kim",
    "reason": "AICP 프로젝트의 궁극적인 목표인 GAN을 이용하여 최적의 자산배분을 하는 포트폴리오 구성 방법론을 찾다가 이 논문을 발견했습니다. 지금까지 GAN으로 시계열 데이터를 생성하는 방법은 있었는데 실제로 포트폴리오를 구성하는 단계 까지는 닿지 못했는데 미래에셋 대회 준비에도 도움이 될 것 같아 선택했습니다. ",
    "url": "https://arxiv.org/abs/1909.10578"
  },
  {
    "date": "2021년 07월 29일",
    "title": "Learning Low-dimensional Representations of Medical concepts",
    "presenter": "Minjoo Choi",
    "reason": "자연어 처리의 Word2Vec에서 사용하는 embedding 기법을 의료정보학 분야에 적용한 연구입니다. Embedding 기법을 다른 분야에서는 어떻게 적용하는지 보려고 합니다. 분야가 낯설기 때문에 [Figure3] 부분과 3.2절의 MRM 메저만 집중해서 보시면 될 것 같습니다. (의학분야 용어가 쏟아져 나오기에(...) 발표를 통해 보시면 좋을 것 같습니다. 다음에는 좀 더 general한 논문 들고 오겠습니다;;)",
    "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5001761/"
  },
  {
    "date": "2021년 07월 29일",
    "title": "Temporal Fusion Transformers\nfor Interpretable Multi-horizon Time Series Forecasting",
    "presenter": "Yoontae Hwang",
    "reason": "NIPS2020, International Journal of forcasting(2021)에 수록된 연구로서 사용할 수 있는 미래의 정보를 이용하여 단기간예측이 아니라 더 먼 미래의 예측도 가능하면서 성능이 가장 좋은 모형입니다. 이 연구에서는 사용되는 아이디어가 매우 참신해서 선택하였습니다. 아이디어에 대한 자세한 설명은 발표때 말씀드리겠습니다",
    "url": "https://www.sciencedirect.com/science/article/pii/S0169207021000637"
  },
  {
    "date": "2021년 07월 22일",
    "title": "Think Globally, Act Locally : A Deep Neural Network Approach to High-Dimensional Time Series Forecasting",
    "presenter": "Randy",
    "reason": "Multi dimensional Time series를 예측하는 방법에 대해서 다룬 논문입니다. Amazon과 University of Texas at Austin에서 합작해서 만든 논문입니다. Global/Local Propertiy들을 모두 학습할 수 있는 방법을 다뤘고, 예측 모델 뿐만 아니라 생성 모델을 만드는 데에서 도움이 될 거 같아서 골라 보았습니다. 특히나 TCN에 대해서 다루기 때문에 살펴볼 가치가 있을 것 같습니다",
    "url": "https://arxiv.org/abs/1905.03806"
  },
  {
    "date": "2021년 07월 22일",
    "title": "An Empirical Exploration of Recurrent Network Architectures",
    "presenter": "Youngbin Lee",
    "reason": "RNN 파라미터 세팅을 어떻게 하면 좋을지에 대해서 살펴 본 논문입니다. RNN에 대해 공부하기 위해 이 논문을 골랐습니다.",
    "url": "http://proceedings.mlr.press/v37/jozefowicz15.html"
  },
  {
    "date": "2021년 07월 15일",
    "title": "XGBoost: A Scalable Tree Boosting System",
    "presenter": "송영석",
    "reason": "환자 상병 명세서 데이터를 통해 치료비를 예측하는 과정에서 boosting algorithm이 유용하게 쓰일거 같아서 성능이 좋다고 알려진 XGBoost의 논문을 받아왔습니다.",
    "url": "https://dl.acm.org/doi/abs/10.1145/2939672.2939785"
  },
  {
    "date": "2021년 07월 15일",
    "title": "Set Transformer: A Framework for Attention-based Permutation-Invariant Neural Networks",
    "presenter": "Sohyeon Kwon",
    "reason": "Self-Attention Mechanism 을 통해 Permutation Invariant 문제를 해결한다는 내용입니다. 현재 진행중인 Permutation Invariant 해결하는 모델과 비슷한것 같아서 골랐습니다.",
    "url": "https://arxiv.org/abs/1810.00825"
  },
  {
    "date": "2021년 07월 08일",
    "title": "DeepAR",
    "presenter": "Yoontae Hwang",
    "reason": "Casual inference 에서 아마존의 수요예측 모델인 Deep AR로 바꿨습니다. 바꾼이유는 내용이 펀더멘탈에서 내용이 저널클럽 목적과 좀 달라서 바꿨습니다. Casual 관련 내용은 다른 외부 저널클럽을 하고 있는데, 관련해서 영상은 7월 14일 유튜브 영상을 따로 링크 달아 두겠습니다. ",
    "url": "https://www.sciencedirect.com/science/article/pii/S0169207019301888"
  },
  {
    "date": "2021년 07월 08일",
    "title": "Momentum, Acceleration, and Reversal",
    "presenter": "Junpyo Park",
    "reason": "모멘텀 측정 지표를 개선하기 위해 만들어진 가속화 모멘텀 입니다. 가속화 모멘텀 전략은 주가 상승 속도의 가속화가 무한정 계속될 수 없기 때문에, 주가가 점차 빠른 속도로 상승한 뒤에는 reversal 이 일어날 것이라는 가정을 전제로 합니다. 가속화 모멘텀 전략과 이를 KOSPI 유니버스에 적용한 결과 등을 소개하려 합니다.",
    "url": "https://www.researchgate.net/publication/294582144_Momentum_Acceleration_and_Reversal"
  },
  {
    "date": "2021년 07월 01일",
    "title": "Reinforcement Learning via Parametric Cost Function Approximation for Multistage Stochastic Programming",
    "presenter": "Yongjae Lee",
    "reason": "multi-stage stochastic programming 문제에 RL을 적용한 논문입니다. 아직 아카이브에 올라와 있는 논문이기는 하지만 MSP 분야의 대가인 Powell 교수님 연구실에서 최근에 적극적으로 홍보하고 있는 토픽이기도 하고, 저도 외부 동료들과 유사하면서도 조금은 다른 맥락의 연구를 하고 있어서 겸사겸사 고르게 되었습니다.",
    "url": "https://arxiv.org/abs/2001.00831"
  },
  {
    "date": "2021년 07월 01일",
    "title": "Individualized Short-term electric load forecasting with DNN based Transfer Learning and Meta Learning",
    "presenter": "Minjoo Choi",
    "reason": "전력 사용량 시계열 데이터에 Transfer Learning과 Meta Learning을 사용해 향후 12시간 후의 전력 사용량 예측을 시도한 연구입니다.\n시계열이라는 측면에서 우리 연구실에서 유용하게 쓰일 것 같아서 가져왔고, 특히, Transfer Learning과 Meta Learnig을 소개하고싶어서 가져왔습니다.",
    "url": "https://ieeexplore.ieee.org/document/9330546"
  },
  {
    "date": "2021년 06월 10일",
    "title": "Latent ODEs for Irregularly-Sampled Time Series",
    "presenter": "Randy",
    "reason": "간격이 일정하지 않은 시계열을 모델링하는 경우가 많은데, RNN을 이용한다고 했을 때 문제점들이 있습니다. 이런 경우에 RNN을 continuous하게 일반화한 ODE-RNN에 대해서 소개하고자 합니다.(지난 발표 때 설명했던 Neural ODE에서 필요한 부분들도 함께 되짚어 가면서 리뷰하도록 하겠습니다.)",
    "url": "https://arxiv.org/abs/1907.03907"
  },
  {
    "date": "2021년 05월 27일",
    "title": "Momentum RNN",
    "presenter": "Sohyeon Kwon",
    "reason": "RNN의 vanishing gradient 이슈를 완화하는 Momentum RNN에 대한 논문입니다. 딥러닝 과목에서 Neural Network Optimization 에 대해 배우는데 Adam 이나 Nesterov accelerated gradient 같은 momentum 기반 Optimization 방법론이 많은 것 같아 더 공부하다가 RNN에서도 Optimization에 쓰이는 것이 재밌어 보여 선택하였습니다.",
    "url": "https://arxiv.org/abs/2006.06919"
  },
  {
    "date": "2021년 05월 20일",
    "title": "Analyzing the analysts: When do recommendations add value?",
    "presenter": "Junpyo Park",
    "reason": "\"애널리스트의 추천은 쓸모가 있는가?\" 에 대한 의문으로 시작된 논문으로 모멘텀 효과를 유행(?) 시켜 전설이 되신 Jegadeesh 교수님께서 쓰셨습니다.",
    "url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.195.9121&rep=rep1&type=pdf"
  },
  {
    "date": "2021년 05월 13일",
    "title": "MLP-Mixer: An all-MLP Architecture for Vision",
    "presenter": "Yoontae Hwang",
    "reason": "최근 SNS에서 MLP만 사용해도 이미지 분류에 효과적이라는 페이퍼입니다. Transfomer 기반의 모델보다 성능은 더 좋지는 않지만 어느정도 상응한다고 해서 많은 이슈가 되고 있어서 한번 읽어보고자 합니다.  (수정이유 : 이전에 선정한 페이퍼는 다양한 모델들 visual bert, detr, vit 같은것도 다 설명해야될것 같은데 이걸 하기엔 너무 시간이 오래걸릴것같아서 나중에 하나하나 설명하겠습니다)",
    "url": "https://arxiv.org/pdf/2105.01601.pdf"
  },
  {
    "date": "2021년 05월 06일",
    "title": "[TreeSHAP] Consistent Individualized Feature Attribution for Tree Ensemble",
    "presenter": "Minjoo Choi",
    "reason": "TreeSHAP (SHAPley Additional exPlanations): Tree 모델에 적용가능한 설명가능한 AI의 방법론 중 하나 입니다. SHAP는 특정 prediction에 대해 각 특성의 중요도(기여도)를 부여합니다. 따라서 SHAP를 이용하면 어떤 특성이 기계학습 모델의 결과에 큰 영향을 미쳤는지 알 수 있습니다.\n이번 발표에서는\n1. SHAP의 이론적 배경과 계산방법\n2. TreeSHAP로 특성들 사이의 상호 작용 효과를 분해하는 것을 보여주고 다양한 시각화 방법도 소개합니다.",
    "url": "https://arxiv.org/abs/1802.03888"
  },
  {
    "date": "2021년 04월 15일",
    "title": "Personalized goal-based investing via multi-stage stochastic goal programming",
    "presenter": "Yongjae Lee",
    "reason": "시험기간을 앞두고 조금 쉬어가는 의미에서 제 연구 중에 하나를 소개하려고 합니다. 4월 말에 보험 연구원에서도 이를 바탕으로 발표할 계획이어서, 겸사겸사 준비합니다. 전반적으로 개인의 자산관리에 대해서 우리 연구실에서 해나가고 싶은 연구의 밑바탕이 되는 연구라고 생각합니다. 개개인의 소비 목표(consumption goal)에 따라 중장기적인 재무 설계를 위한 최적화 모델을 간단하게 제시한 연구이고, 인트로에 소개한 여러 내용은 특히 잘 봐두면 좋을 것 같습니다.",
    "url": "https://www.tandfonline.com/doi/full/10.1080/14697688.2019.1662079"
  },
  {
    "date": "2021년 04월 08일",
    "title": "Neural Ordinary Differential Equations",
    "presenter": "Randy",
    "reason": "Residual network의 hidden state들의 값의 생성 과정이 discrete한 반면에 ODE(Ordinary Differential Equation)를 이용해서 hidden state를 모델링하는 과정에 대해서 설명한 과정입니다. ODE Network로 모델링 하였을 때  memory efficiency, Adaptative computation 등의 기대효과가 있습니다. 특히나 continuous time-series model을 구축할 수 있다는 부분에서 흥미를 가지고 있었기 때문에 골라보았습니다.",
    "url": "https://arxiv.org/abs/1806.07366"
  },
  {
    "date": "2021년 04월 01일",
    "title": "Input Convex Neural Networks",
    "presenter": "Yongjae Lee",
    "reason": "Convex 수업 시간에 간단하게 소개했던 2017년 ICML 논문을 여기도 공유합니다. Neural network이 기본적으로는 affine combination과 activation function의 composition으로 이루어진 함수이기 때문에, 몇 가지 제약조건만 잘 만족하면 convex function이 될 수 있습니다. 이 논문은 convexity를 유지하면서 충분한 modeling capacity를 가질 수 있는 neural network의 조건을 제시하고 이를 기반으로 한 간단한 실험을 보여주고 있습니다.",
    "url": "https://arxiv.org/pdf/1609.07152.pdf"
  },
  {
    "date": "2021년 04월 01일",
    "title": "Modeling Similarities Among Multi-Dimensional Financial Time Series",
    "presenter": "Sohyeon Kwon",
    "reason": "Pairs trading 전략에서 correlation 대신 데이터의 intrinsic 한 특성을 가진 tensor를 기반으로한 similarity 를 사용할 수 있다는 논문입니다. GAN 으로 생성한 데이터간의 similarity를 측정하는 방법으로 사용될 수 있을까 싶어서 골랐습니다.",
    "url": "https://ieeexplore.ieee.org/document/8425030"
  },
  {
    "date": "2021년 03월 25일",
    "title": "Classifying and Understanding Financial Data Using Graph Neural Network",
    "presenter": "Junpyo Park",
    "reason": "J.P.Morgan AI 리서치팀에서 나온 GNN 관련 페이퍼 입니다. 4가지의 데이터셋(one synthetic and three reals)에 어떤 방식으로 그래프를 생성하였고 이를 학습시킴으로써 어떤 결과를 얻을 수 있었는지 정리하고 있습니다.",
    "url": "https://aaai-kdf2020.github.io/assets/pdfs/kdf2020_paper_21.pdf"
  },
  {
    "date": "2021년 03월 18일",
    "title": "Neural Processes",
    "presenter": "Yoontae Hwang",
    "reason": "2018 딥마인드 논문으로 Neural Process가 함수의 분포를 GP와는 달리 커널함수를 사용하지 않고 잘 추정한다는 논문입니다.",
    "url": "https://arxiv.org/abs/1807.01622"
  },
  {
    "date": "2021년 02월 16일",
    "title": "Every Model Learned by Gradient Descent Is Approximately a Kernel Machine",
    "presenter": "Yongjae Lee",
    "reason": "gradient descent로 학습된 모든 모델 (뉴럴넷 포함)이 사실은 kernel machine으로 볼 수 있다는 연구입니다. 아직 정식 publish가 안되어서 조심스럽기는 하지만 이미 정말 많은 주목을 받고 있는 연구이기도 하고, 현재 연구 중인 large-scale multi-stage stochastic programming과도 관련이 좀 있어서 정해봤습니다. 핵심 내용 위주로 짚고 넘어갈 계획입니다.",
    "url": "https://arxiv.org/abs/2012.00152"
  },
  {
    "date": "2021년 02월 16일",
    "title": "60 Years of portfolio optimization: Practical challenges and current trends",
    "presenter": "Minjoo Choi",
    "reason": "포트폴리오 최적화에 관한 2013년 까지의 연구를 정리한 리뷰 논문입니다. 16일에는 마지막 4절 - 포트폴리오 최적화에 관한 최신 트렌드 파트를 살펴봅니다.",
    "url": "https://www.sciencedirect.com/science/article/pii/S0377221713008898"
  },
  {
    "date": "2021년 02월 09일",
    "title": "Multivariate Time Series Imputation with\nGenerative Adversarial Networks",
    "presenter": "Randy",
    "reason": "Multivariate time series를 GAN으로 generate 하는 데에 있어서 missing value들을 어떤 식으로 처리할지에 대한 논문입니다. ",
    "url": "https://proceedings.neurips.cc/paper/2018/hash/96b9bff013acedfb1d140579e2fbeb63-Abstract.html"
  },
  {
    "date": "2021년 02월 09일",
    "title": "A Quantitative Approach to Tactical Asset Allocation",
    "presenter": "Junpyo Park",
    "reason": "듀얼 모멘텀의 원조격인 논문으로 거의 그래프와 표 위주라 쉽게 읽을 수 있습니다. TAA의 시작이 되는 논문이라 생각해 선택하였습니다.",
    "url": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=962461"
  },
  {
    "date": "2021년 02월 02일",
    "title": "Structure of a Global Network of Financial Companies Based on Transfer Entropy",
    "presenter": "Sohyeon Kwon",
    "reason": "Transfer Entropy 개념에 기반하여 큰 회사들간의 관계를 주가의 관점에서 바라본 논문입니다. 더 나아가 각 financial sector 별로 다른 어떤 sector에 영향을 많이 미치는지, 그 network 를 이해할 수 있고, 금융 위기 시 그 위험이 다른 나라로 어떤식으로 퍼져나가는지를 transfer entropy의 개념으로 해석할 수 있는 새로운 개념의 논문입니다.",
    "url": "https://www.mdpi.com/1099-4300/16/8/4443"
  },
  {
    "date": "2021년 02월 02일",
    "title": "Deep Clustering via Clustering the local manifold of an Autoencoder Embedding",
    "presenter": "Yoontae Hwang",
    "reason": "딥러닝에서 Manifold Learning은 매우 중요합니다. 이번 논문에서는 이에 대한 내용과 더불어 Latent Space에서 Clustering Algorithm(2020)을 살펴보기위해 선택하였습니다.  논문은 왼쪽제목과 같은 논문을 리뷰할 예정인데, 다른 논문에서 신기한 내용이 많아서 30분 발표시간 내에 2개의 논문을 리뷰할 수도 있을것 같습니다. (확정되면 수정하도록하겠습니다)",
    "url": "https://arxiv.org/abs/1908.05968"
  },
  {
    "date": "2021년 01월 26일",
    "title": "Determinants of Portfolio performance",
    "presenter": "Yongjae Lee",
    "reason": "이 논문과 후속작, 그리고 관련된 연구들에 대하여 소개할 계획입니다. 전반적으로는 자산배분(asset allocation) 결정이 전체적인 투자에서 얼마나 중요한지에 대한 이야기이고 워낙 많이 회자되는 내용이기도 하고 연구에도 많이 cite 되곤 하니 알아두면 좋을 것 같아서 골랐습니다. 분석 자체는 엄청 간단하고 쉬우니 부담 없이 읽어도 좋을 것 같습니다.",
    "url": "https://www.tandfonline.com/doi/abs/10.2469/faj.v42.n4.39"
  },
  {
    "date": "2021년 01월 26일",
    "title": "60 Years of portfolio optimization: Practical challenges and current trends",
    "presenter": "Minjoo Choi",
    "reason": "포트폴리오 최적화에 관한 2013년 까지의 연구를 정리한 리뷰 논문입니다. 크게 두 파트로 나누어져 있는데: 3절 - 포트폴리오 최적화를 현실적으로 수정한 파트, 4절 - 포트폴리오 최적화에 관한 최신 트렌드 파트 입니다.\n26일에는 일단 3절 까지 살펴보겠습니다.",
    "url": "https://www.sciencedirect.com/science/article/pii/S0377221713008898"
  },
  {
    "date": "2021년 01월 19일",
    "title": "Time-series Generative Adversarial Networks",
    "presenter": "Randy",
    "reason": "time-series를 GAN을 통해서 학습 시키는데에 있어서 time-series의 dynamics 또한 반영하는 방법을 모색하게 위해서 골랐습니다.",
    "url": "https://proceedings.neurips.cc/paper/2019/hash/c9efe5f26cd17ba6216bbe2a7d26d490-Abstract.html"
  },
  {
    "date": "2021년 01월 19일",
    "title": "TadGAN: Time Series Anomaly Detection Using GANs",
    "presenter": "Junpyo Park",
    "reason": "GAN을 활용한 Time Series Anomaly Detection 의 가장 최신 논문으로 이전에 살펴보았던 MAD GAN을 Evaluation 벤치마크로 사용하고 있어 알고리즘의 어떤 부분이 개선 되었는지 살펴보기 위해 골랐습니다.",
    "url": "https://arxiv.org/pdf/2009.07769.pdf"
  },
  {
    "date": "2021년 01월 12일",
    "title": "Modeling financial time-series with generative adversarial networks",
    "presenter": "Sohyeon Kwon",
    "reason": "FINGAN 으로 금융 시계열 데이터를 생성할 때 구체적으로 어떤 점을 확인해야하는지 알기 위해",
    "url": "https://www.sciencedirect.com/science/article/abs/pii/S0378437119307277"
  },
  {
    "date": "2021년 01월 12일",
    "title": "Residual momentum",
    "presenter": "Yoontae Hwang",
    "reason": "투자자 분석에 언젠가 사용할 수도 있을것 같아서 골랐습니다. ppt파일은 완성 직전 단계부터 미리 올려두겠습니다.",
    "url": "https://www.sciencedirect.com/science/article/pii/S0927539811000041"
  },
  {
    "date": "2020년 10월 22일",
    "title": "Household Finance",
    "presenter": "Yoontae Hwang",
    "reason": "가계 금융건강검진 인공지능 모델 연구와 관련",
    "url": "https://onlinelibrary.wiley.com/doi/full/10.1111/j.1540-6261.2006.00883.x"
  },
  {
    "date": "2020년 10월 07일",
    "title": "The Voice of Optimization",
    "presenter": "Yongjae Lee",
    "reason": "최적화 문제를 parameter만 바꿔가며 여러번 풀어야 할 때 사용될 수 있는 방법론",
    "url": "https://link.springer.com/article/10.1007/s10994-020-05893-5"
  }
]